{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to c:\\users\\19824\\appdata\\local\\temp\\pip-req-build-_h0r9liy\n",
      "  Resolved https://github.com/openai/CLIP.git to commit b46f5ac7587d2e1862f8b7b1573179d80dcdd620\n",
      "Requirement already satisfied: ftfy in c:\\programdata\\anaconda3\\lib\\site-packages (from clip==1.0) (6.1.1)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from clip==1.0) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from clip==1.0) (4.62.3)\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (from clip==1.0) (1.11.0+cu113)\n",
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (from clip==1.0) (0.12.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch->clip==1.0) (3.10.0.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision->clip==1.0) (2.27.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/openai/CLIP.git 'C:\\Users\\19824\\AppData\\Local\\Temp\\pip-req-build-_h0r9liy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision->clip==1.0) (8.4.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision->clip==1.0) (1.20.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision->clip==1.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision->clip==1.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision->clip==1.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision->clip==1.0) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->clip==1.0) (0.4.4)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "device is cuda\n",
      "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/openai/CLIP.git\n",
    "%pip install tqdm\n",
    "\n",
    "import re\n",
    "import clip\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# setup torch and clip model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device is\", device)\n",
    "print(clip.available_models())\n",
    "model, preprocess = clip.load('ViT-L/14@336px', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned data from csv\n",
    "train = \"../Input/df_train_aug_clean.csv\"\n",
    "test = \"../Input/df_test_aug_clean.csv\"\n",
    "\n",
    "# train data\n",
    "with open(train) as file:\n",
    "    lines=[line for line in file]\n",
    "    df_train = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
    "\n",
    "# test data\n",
    "with open(test) as file:\n",
    "    lines=[line for line in file]\n",
    "    df_test = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 self defined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset\n",
    "class Trainset(Dataset):\n",
    "    def __init__(self, df):\n",
    "\n",
    "        print(\"initializing trainset...\")\n",
    "\n",
    "        # init\n",
    "        self.combined_feature = df.ImageID\n",
    "\n",
    "        # image to image features       \n",
    "        self.image_raw = df.ImageID\n",
    "        self.image_train = [None]*len(df)\n",
    "        for i in trange(len(df)):\n",
    "            image = Image.open(\"../Input/data/{}\".format(self.image_raw[i]))\n",
    "            augmenter = transforms.RandAugment()\n",
    "            image = augmenter(image)\n",
    "            image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                image_features = model.encode_image(image_input)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            self.image_train[i] = image_features\n",
    "\n",
    "        # caption to text features\n",
    "        self.caption_raw = df.Caption\n",
    "        self.caption_train = [None]*len(df)\n",
    "        for i in trange(len(df)):\n",
    "            text_inputs = clip.tokenize(self.caption_raw[i]).to(device)\n",
    "            with torch.no_grad():\n",
    "                text_features = model.encode_text(text_inputs)\n",
    "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "            self.caption_train[i] = text_features\n",
    "\n",
    "        # concatenate image and text features\n",
    "        for i in trange(len(df)):\n",
    "            self.combined_feature[i] = torch.cat((self.image_train[i], self.caption_train[i]),1)\n",
    "\n",
    "        # one-hot encode labels\n",
    "        self.labels_train = torch.zeros([len(df),20],dtype=torch.float32)\n",
    "        for i in range(len(df)):\n",
    "            for j in df.Labels[i].split(\" \"):\n",
    "                self.labels_train[i][int(j)] = 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.combined_feature)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self): raise IndexError\n",
    "        return self.combined_feature[idx], self.labels_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset\n",
    "class Testset(Dataset):\n",
    "    def __init__(self, df):\n",
    "\n",
    "        print(\"initializing testset...\")\n",
    "        \n",
    "        # init\n",
    "        self.combined_feature = df.ImageID\n",
    "\n",
    "        # image to image features\n",
    "        self.image_raw = df.ImageID\n",
    "        self.image_test = [None]*len(df)\n",
    "        for i in trange(len(df)):\n",
    "            image = Image.open(\"../Input/data/{}\".format(self.image_raw[i]))\n",
    "            image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                image_features = model.encode_image(image_input)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            self.image_test[i] = image_features\n",
    "\n",
    "        # caption to text features\n",
    "        self.caption_raw = df.Caption\n",
    "        self.caption_test = [None]*len(df)\n",
    "        for i in trange(len(df)):\n",
    "            text_inputs = clip.tokenize(self.caption_raw[i]).to(device)\n",
    "            with torch.no_grad():\n",
    "                text_features = model.encode_text(text_inputs)\n",
    "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "            self.caption_test[i] = text_features\n",
    "\n",
    "        # concatenate image and text features\n",
    "        for i in trange(len(df)):\n",
    "            self.combined_feature[i] = torch.cat((self.image_test[i], self.caption_test[i]),1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.combined_feature)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self): raise IndexError\n",
    "        return self.combined_feature[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 load into dataloader and encode with clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing trainset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f4e200b99040feb9bf36fded7aba5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d3d24a1aff4786950cc1d2d375d95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb9bed228ce4138a1baad0b78e882d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000 1000\n",
      "initializing testset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7673ca23b95e45b383f5cc78fe6bb45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c058568f9c04e979be6145a6cb63633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175371fc910d4bb5a5ad36d3d2542c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = Trainset(df_train)\n",
    "train_set, val_set = torch.utils.data.random_split(train_set,[29000,1000])\n",
    "print(len(train_set), len(val_set))\n",
    "\n",
    "test_set = Testset(df_test)\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(768*2, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc = nn.Linear(1024, 18)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 model initialization & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "net = Net().to(device)\n",
    "\n",
    "# criterion = torch.nn.MultiLabelSoftMarginLoss()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = lr) # Using Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_set:\n",
    "            features = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(features.float())\n",
    "            # the label with the positive energy is what we choose as prediction\n",
    "            ones = torch.ones(18).to(device)\n",
    "            zeros = torch.zeros(18).to(device)\n",
    "            sig = nn.Sigmoid()\n",
    "            outputs = sig(outputs)\n",
    "            outputs_01 = torch.where(outputs>0.53, ones, zeros).to(device)\n",
    "            outputs_01 = torch.cat((torch.zeros(1).to(device), outputs_01[:11], torch.zeros(1).to(device), outputs_01[11:]))\n",
    "            \n",
    "            label = \"\"\n",
    "            for i in range(len(outputs_01)):\n",
    "                if outputs_01[i] == 1:\n",
    "                    label += \"{} \".format(i)\n",
    "\n",
    "            if len(label) == 0:\n",
    "                # when no positive predictions,\n",
    "                # either take the most possible label, \n",
    "                outputs[0] = -100 # no label 1\n",
    "                the_one = int(torch.argmax(outputs))\n",
    "                if the_one <= 10:\n",
    "                    the_one += 1\n",
    "                else:\n",
    "                    the_one += 2\n",
    "                result.append(str(the_one))\n",
    "                \n",
    "                # or just predict nothing. not performing very well\n",
    "                # result.append(\"\") \n",
    "            else:\n",
    "                result.append(label.rstrip(\" \"))\n",
    "                \n",
    "        print(\"Finished predicting\")\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 save result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(result):\n",
    "    with open(test) as file:\n",
    "        lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
    "        df2 = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
    "\n",
    "    df = pd.DataFrame({\"ImageID\": df2.ImageID, 'Labels': result})\n",
    "    df.to_csv('../Output/result.csv', index=False)  \n",
    "\n",
    "    print(\"successfully saved to 'result.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global best_acc \n",
    "best_acc = 0\n",
    "def validate():\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_set:\n",
    "            features, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(features.float())\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            ones = torch.ones(18).to(device)\n",
    "            zeros = torch.zeros(18).to(device)\n",
    "            sig = nn.Sigmoid()\n",
    "            outputs = sig(outputs)\n",
    "            outputs = torch.where(outputs>0.53, ones, zeros).to(device)\n",
    "            outputs = torch.cat((torch.zeros(1).to(device), outputs[:11], torch.zeros(1).to(device), outputs[11:])).to(device)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            correct += (outputs == labels.to(device)).sum().item()\n",
    "\n",
    "    # f1-score\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data in val_set:\n",
    "            features, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(features.float())\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            ones = torch.ones(18).to(device)\n",
    "            zeros = torch.zeros(18).to(device)\n",
    "            sig = nn.Sigmoid()\n",
    "            outputs = sig(outputs)\n",
    "            outputs = torch.where(outputs>0.53, ones, zeros).to(device)\n",
    "            outputs = torch.cat((torch.zeros(1).to(device), outputs[:11], torch.zeros(1).to(device), outputs[11:])).to(device)\n",
    "            y_true.append(labels.tolist())\n",
    "            y_pred.append(outputs.tolist())\n",
    "\n",
    "\n",
    "    # print(f'Accuracy of the network: {100 * correct // total} %')\n",
    "    print('Average F1 score of the network: {:.4f}'.format(f1_score(y_true=np.array(y_true), y_pred=np.array(y_pred), average='samples')))\n",
    "    print('Average recall_score score of the network: {:.4f}'.format(recall_score(y_true=np.array(y_true), y_pred=np.array(y_pred), average='samples')))\n",
    "    print('Average precision_score score of the network: {:.4f}'.format(precision_score(y_true=np.array(y_true), y_pred=np.array(y_pred), average='samples')))\n",
    "    print(classification_report(y_true=np.array(y_true), y_pred=np.array(y_pred)))\n",
    "\n",
    "    # save prediction result to csv if this epoch performs the best\n",
    "    global best_acc\n",
    "    if f1_score(y_true=np.array(y_true), y_pred=np.array(y_pred), average='samples') >= best_acc:\n",
    "        best_acc = f1_score(y_true=np.array(y_true), y_pred=np.array(y_pred), average='samples')\n",
    "        final_result = predict()\n",
    "        save_result(final_result)\n",
    "        print(\"Yet the Best epoch, saving result. BEST F1:\",best_acc,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 training process\n",
    "after running this sections, the final result of prediction will be saved in result.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5db746ccf48409db7187c06b87666af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/  100] loss: 0.198\n",
      "Average F1 score of the network: 0.6629\n",
      "Average recall_score score of the network: 0.6175\n",
      "Average precision_score score of the network: 0.7690\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.89      0.96      0.93       761\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.60      0.27      0.38       153\n",
      "           4       0.00      0.00      0.00        42\n",
      "           5       1.00      0.13      0.24        30\n",
      "           6       0.00      0.00      0.00        38\n",
      "           7       0.00      0.00      0.00        39\n",
      "           8       0.00      0.00      0.00        77\n",
      "           9       0.00      0.00      0.00        44\n",
      "          10       0.00      0.00      0.00        48\n",
      "          11       0.00      0.00      0.00        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00        19\n",
      "          14       0.00      0.00      0.00        12\n",
      "          15       0.00      0.00      0.00        53\n",
      "          16       0.00      0.00      0.00        27\n",
      "          17       1.00      0.29      0.45        55\n",
      "          18       1.00      0.27      0.43        44\n",
      "          19       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.87      0.52      0.65      1542\n",
      "   macro avg       0.22      0.10      0.12      1542\n",
      "weighted avg       0.58      0.52      0.53      1542\n",
      " samples avg       0.77      0.62      0.66      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.662947619047619 \n",
      "\n",
      "[1/  200] loss: 0.108\n",
      "Average F1 score of the network: 0.8228\n",
      "Average recall_score score of the network: 0.7930\n",
      "Average precision_score score of the network: 0.9052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.93      0.94       761\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.59      0.35      0.44       153\n",
      "           4       0.93      0.67      0.78        42\n",
      "           5       1.00      0.93      0.97        30\n",
      "           6       0.96      0.66      0.78        38\n",
      "           7       0.97      0.90      0.93        39\n",
      "           8       0.59      0.30      0.40        77\n",
      "           9       1.00      0.20      0.34        44\n",
      "          10       1.00      0.21      0.34        48\n",
      "          11       0.00      0.00      0.00        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00        19\n",
      "          14       0.00      0.00      0.00        12\n",
      "          15       0.94      0.28      0.43        53\n",
      "          16       1.00      0.74      0.85        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       1.00      0.64      0.78        44\n",
      "          19       0.96      0.92      0.94        52\n",
      "\n",
      "   micro avg       0.92      0.70      0.79      1542\n",
      "   macro avg       0.64      0.43      0.49      1542\n",
      "weighted avg       0.86      0.70      0.75      1542\n",
      " samples avg       0.91      0.79      0.82      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.822820634920635 \n",
      "\n",
      "[1/  300] loss: 0.087\n",
      "Average F1 score of the network: 0.8313\n",
      "Average recall_score score of the network: 0.8040\n",
      "Average precision_score score of the network: 0.9081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.91      0.94       761\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.63      0.31      0.42       153\n",
      "           4       0.78      0.76      0.77        42\n",
      "           5       1.00      0.93      0.97        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       1.00      0.08      0.14        77\n",
      "           9       0.91      0.48      0.63        44\n",
      "          10       0.86      0.38      0.52        48\n",
      "          11       1.00      0.08      0.14        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00        19\n",
      "          14       0.00      0.00      0.00        12\n",
      "          15       0.78      0.34      0.47        53\n",
      "          16       1.00      0.89      0.94        27\n",
      "          17       0.84      0.93      0.88        55\n",
      "          18       0.94      0.73      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.70      0.80      1542\n",
      "   macro avg       0.68      0.47      0.52      1542\n",
      "weighted avg       0.88      0.70      0.75      1542\n",
      " samples avg       0.91      0.80      0.83      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8313309523809523 \n",
      "\n",
      "[1/  400] loss: 0.088\n",
      "Average F1 score of the network: 0.8460\n",
      "Average recall_score score of the network: 0.8215\n",
      "Average precision_score score of the network: 0.9167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.99      0.89      0.93       761\n",
      "           2       1.00      0.03      0.06        35\n",
      "           3       0.54      0.49      0.51       153\n",
      "           4       0.97      0.69      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.66      0.79        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.80      0.48      0.60        77\n",
      "           9       0.96      0.55      0.70        44\n",
      "          10       0.90      0.38      0.53        48\n",
      "          11       1.00      0.85      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00        19\n",
      "          14       0.00      0.00      0.00        12\n",
      "          15       0.94      0.30      0.46        53\n",
      "          16       0.96      0.85      0.90        27\n",
      "          17       0.98      0.84      0.90        55\n",
      "          18       0.97      0.73      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.73      0.82      1542\n",
      "   macro avg       0.75      0.53      0.59      1542\n",
      "weighted avg       0.91      0.73      0.79      1542\n",
      " samples avg       0.92      0.82      0.85      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8460023809523809 \n",
      "\n",
      "[1/  500] loss: 0.082\n",
      "Average F1 score of the network: 0.8697\n",
      "Average recall_score score of the network: 0.8528\n",
      "Average precision_score score of the network: 0.9302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.94      0.94       761\n",
      "           2       1.00      0.31      0.48        35\n",
      "           3       0.67      0.42      0.52       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.66      0.79        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.90      0.36      0.52        77\n",
      "           9       0.97      0.64      0.77        44\n",
      "          10       0.76      0.60      0.67        48\n",
      "          11       0.60      0.92      0.73        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.26      0.42        19\n",
      "          14       0.00      0.00      0.00        12\n",
      "          15       0.94      0.30      0.46        53\n",
      "          16       1.00      0.85      0.92        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.97      0.73      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.77      0.84      1542\n",
      "   macro avg       0.78      0.57      0.63      1542\n",
      "weighted avg       0.91      0.77      0.81      1542\n",
      " samples avg       0.93      0.85      0.87      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8697007936507937 \n",
      "\n",
      "[1/  600] loss: 0.087\n",
      "Average F1 score of the network: 0.8511\n",
      "Average recall_score score of the network: 0.8198\n",
      "Average precision_score score of the network: 0.9303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.98      0.91      0.94       761\n",
      "           2       0.93      0.37      0.53        35\n",
      "           3       0.86      0.16      0.27       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.89      0.40      0.55        77\n",
      "           9       0.89      0.57      0.69        44\n",
      "          10       0.95      0.44      0.60        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.16      0.27        19\n",
      "          14       0.00      0.00      0.00        12\n",
      "          15       0.94      0.32      0.48        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.91      0.68      0.78        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.96      0.72      0.83      1542\n",
      "   macro avg       0.80      0.55      0.62      1542\n",
      "weighted avg       0.94      0.72      0.79      1542\n",
      " samples avg       0.93      0.82      0.85      1542\n",
      "\n",
      "[1/  700] loss: 0.081\n",
      "Average F1 score of the network: 0.8669\n",
      "Average recall_score score of the network: 0.8339\n",
      "Average precision_score score of the network: 0.9518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.98      0.91      0.94       761\n",
      "           2       1.00      0.29      0.44        35\n",
      "           3       0.86      0.20      0.32       153\n",
      "           4       1.00      0.67      0.80        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.97      0.90      0.93        39\n",
      "           8       0.96      0.35      0.51        77\n",
      "           9       0.87      0.61      0.72        44\n",
      "          10       0.87      0.54      0.67        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.17      0.29        12\n",
      "          15       0.86      0.36      0.51        53\n",
      "          16       0.86      0.93      0.89        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.96      0.73      0.83      1542\n",
      "   macro avg       0.85      0.58      0.66      1542\n",
      "weighted avg       0.95      0.73      0.80      1542\n",
      " samples avg       0.95      0.83      0.87      1542\n",
      "\n",
      "[1/  800] loss: 0.081\n",
      "Average F1 score of the network: 0.8734\n",
      "Average recall_score score of the network: 0.8467\n",
      "Average precision_score score of the network: 0.9472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.94       761\n",
      "           2       1.00      0.40      0.57        35\n",
      "           3       0.75      0.38      0.50       153\n",
      "           4       1.00      0.60      0.75        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.97      0.39      0.56        77\n",
      "           9       1.00      0.45      0.62        44\n",
      "          10       0.95      0.42      0.58        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.58      0.73        19\n",
      "          14       1.00      0.42      0.59        12\n",
      "          15       0.89      0.32      0.47        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       1.00      0.90      0.95        52\n",
      "\n",
      "   micro avg       0.94      0.76      0.84      1542\n",
      "   macro avg       0.86      0.59      0.68      1542\n",
      "weighted avg       0.94      0.76      0.82      1542\n",
      " samples avg       0.95      0.85      0.87      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8734095238095237 \n",
      "\n",
      "[1/  900] loss: 0.079\n",
      "Average F1 score of the network: 0.8821\n",
      "Average recall_score score of the network: 0.8664\n",
      "Average precision_score score of the network: 0.9414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.92      0.94       761\n",
      "           2       1.00      0.46      0.63        35\n",
      "           3       0.63      0.48      0.55       153\n",
      "           4       0.89      0.76      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       1.00      0.66      0.79        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       1.00      0.36      0.53        77\n",
      "           9       0.88      0.64      0.74        44\n",
      "          10       0.78      0.65      0.70        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.88      0.74      0.80        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.88      0.40      0.55        53\n",
      "          16       1.00      0.89      0.94        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.92      0.80      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.78      0.85      1542\n",
      "   macro avg       0.83      0.65      0.71      1542\n",
      "weighted avg       0.92      0.78      0.84      1542\n",
      " samples avg       0.94      0.87      0.88      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8821269841269841 \n",
      "\n",
      "[1/ 1000] loss: 0.076\n",
      "Average F1 score of the network: 0.8870\n",
      "Average recall_score score of the network: 0.8707\n",
      "Average precision_score score of the network: 0.9446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.93      0.94       761\n",
      "           2       1.00      0.43      0.60        35\n",
      "           3       0.68      0.52      0.59       153\n",
      "           4       0.94      0.76      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.97      0.36      0.53        77\n",
      "           9       0.83      0.68      0.75        44\n",
      "          10       0.93      0.56      0.70        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.74      0.74      0.74        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.83      0.38      0.52        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.93      0.91      0.92        55\n",
      "          18       0.97      0.70      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.79      0.85      1542\n",
      "   macro avg       0.83      0.65      0.71      1542\n",
      "weighted avg       0.92      0.79      0.84      1542\n",
      " samples avg       0.94      0.87      0.89      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8869714285714285 \n",
      "\n",
      "[1/ 1100] loss: 0.077\n",
      "Average F1 score of the network: 0.8845\n",
      "Average recall_score score of the network: 0.8744\n",
      "Average precision_score score of the network: 0.9387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.92      0.94       761\n",
      "           2       1.00      0.46      0.63        35\n",
      "           3       0.62      0.54      0.57       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.94      0.76      0.84        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.73      0.52      0.61        77\n",
      "           9       0.86      0.68      0.76        44\n",
      "          10       0.96      0.54      0.69        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.90      0.36      0.51        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.97      0.70      0.82        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.92      0.79      0.85      1542\n",
      "   macro avg       0.83      0.65      0.72      1542\n",
      "weighted avg       0.91      0.79      0.84      1542\n",
      " samples avg       0.94      0.87      0.88      1542\n",
      "\n",
      "[1/ 1200] loss: 0.075\n",
      "Average F1 score of the network: 0.8724\n",
      "Average recall_score score of the network: 0.8436\n",
      "Average precision_score score of the network: 0.9515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.99      0.91      0.95       761\n",
      "           2       1.00      0.46      0.63        35\n",
      "           3       0.82      0.26      0.40       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.85      0.45      0.59        77\n",
      "           9       0.90      0.61      0.73        44\n",
      "          10       0.67      0.62      0.65        48\n",
      "          11       0.91      0.77      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.58      0.73        19\n",
      "          14       1.00      0.42      0.59        12\n",
      "          15       0.94      0.28      0.43        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.87      0.77      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.95      0.75      0.84      1542\n",
      "   macro avg       0.84      0.61      0.69      1542\n",
      "weighted avg       0.94      0.75      0.82      1542\n",
      " samples avg       0.95      0.84      0.87      1542\n",
      "\n",
      "[1/ 1300] loss: 0.074\n",
      "Average F1 score of the network: 0.8843\n",
      "Average recall_score score of the network: 0.8690\n",
      "Average precision_score score of the network: 0.9419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       1.00      0.46      0.63        35\n",
      "           3       0.62      0.50      0.55       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       1.00      0.87      0.93        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.87      0.44      0.59        77\n",
      "           9       0.96      0.59      0.73        44\n",
      "          10       0.95      0.44      0.60        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.74      0.82        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.90      0.34      0.49        53\n",
      "          16       0.93      0.93      0.93        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       1.00      0.68      0.81        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.79      0.85      1542\n",
      "   macro avg       0.84      0.63      0.71      1542\n",
      "weighted avg       0.92      0.79      0.84      1542\n",
      " samples avg       0.94      0.87      0.88      1542\n",
      "\n",
      "[1/ 1400] loss: 0.072\n",
      "Average F1 score of the network: 0.8885\n",
      "Average recall_score score of the network: 0.8750\n",
      "Average precision_score score of the network: 0.9440\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.95       761\n",
      "           2       0.94      0.46      0.62        35\n",
      "           3       0.76      0.44      0.56       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       1.00      0.66      0.79        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.82      0.52      0.63        77\n",
      "           9       0.89      0.57      0.69        44\n",
      "          10       0.70      0.54      0.61        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.73      0.45      0.56        53\n",
      "          16       0.93      0.93      0.93        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.79      0.86      1542\n",
      "   macro avg       0.83      0.64      0.71      1542\n",
      "weighted avg       0.92      0.79      0.84      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8884793650793651 \n",
      "\n",
      "[1/ 1500] loss: 0.068\n",
      "Average F1 score of the network: 0.8837\n",
      "Average recall_score score of the network: 0.8598\n",
      "Average precision_score score of the network: 0.9519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.94      0.46      0.62        35\n",
      "           3       0.78      0.35      0.48       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.63      0.77        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.92      0.43      0.58        77\n",
      "           9       0.96      0.50      0.66        44\n",
      "          10       0.52      0.69      0.59        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.95      0.36      0.52        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.94      0.77      0.85      1542\n",
      "   macro avg       0.84      0.63      0.70      1542\n",
      "weighted avg       0.94      0.77      0.83      1542\n",
      " samples avg       0.95      0.86      0.88      1542\n",
      "\n",
      "[1/ 1600] loss: 0.074\n",
      "Average F1 score of the network: 0.8853\n",
      "Average recall_score score of the network: 0.8658\n",
      "Average precision_score score of the network: 0.9486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.96      0.95       761\n",
      "           2       1.00      0.49      0.65        35\n",
      "           3       0.79      0.37      0.50       153\n",
      "           4       1.00      0.64      0.78        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.63      0.77        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.87      0.44      0.59        77\n",
      "           9       0.96      0.57      0.71        44\n",
      "          10       0.84      0.56      0.68        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       1.00      0.34      0.51        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       1.00      0.84      0.91        55\n",
      "          18       0.95      0.80      0.86        44\n",
      "          19       1.00      0.92      0.96        52\n",
      "\n",
      "   micro avg       0.94      0.78      0.85      1542\n",
      "   macro avg       0.86      0.62      0.71      1542\n",
      "weighted avg       0.93      0.78      0.83      1542\n",
      " samples avg       0.95      0.87      0.89      1542\n",
      "\n",
      "[1/ 1700] loss: 0.076\n",
      "Average F1 score of the network: 0.8892\n",
      "Average recall_score score of the network: 0.8782\n",
      "Average precision_score score of the network: 0.9426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.95       761\n",
      "           2       0.94      0.46      0.62        35\n",
      "           3       0.63      0.54      0.58       153\n",
      "           4       0.91      0.74      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.89      0.43      0.58        77\n",
      "           9       0.93      0.64      0.76        44\n",
      "          10       0.86      0.50      0.63        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.42      0.59        12\n",
      "          15       0.92      0.42      0.57        53\n",
      "          16       0.93      0.93      0.93        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.80      0.85      1542\n",
      "   macro avg       0.83      0.64      0.71      1542\n",
      "weighted avg       0.91      0.80      0.84      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8891507936507935 \n",
      "\n",
      "[1/ 1800] loss: 0.069\n",
      "Average F1 score of the network: 0.8908\n",
      "Average recall_score score of the network: 0.8812\n",
      "Average precision_score score of the network: 0.9429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       1.00      0.46      0.63        35\n",
      "           3       0.66      0.50      0.57       153\n",
      "           4       1.00      0.71      0.83        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.96      0.68      0.80        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.79      0.53      0.64        77\n",
      "           9       0.96      0.61      0.75        44\n",
      "          10       0.90      0.54      0.68        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.95      0.36      0.52        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.81      0.80      0.80        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.80      0.86      1542\n",
      "   macro avg       0.83      0.65      0.72      1542\n",
      "weighted avg       0.91      0.80      0.84      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8908420634920635 \n",
      "\n",
      "[2/  100] loss: 0.063\n",
      "Average F1 score of the network: 0.8927\n",
      "Average recall_score score of the network: 0.8696\n",
      "Average precision_score score of the network: 0.9591\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.95       761\n",
      "           2       0.77      0.49      0.60        35\n",
      "           3       0.70      0.41      0.52       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.89      0.44      0.59        77\n",
      "           9       0.93      0.61      0.74        44\n",
      "          10       0.87      0.56      0.68        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.94      0.30      0.46        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.94      0.78      0.86      1542\n",
      "   macro avg       0.84      0.64      0.71      1542\n",
      "weighted avg       0.93      0.78      0.84      1542\n",
      " samples avg       0.96      0.87      0.89      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.892663492063492 \n",
      "\n",
      "[2/  200] loss: 0.062\n",
      "Average F1 score of the network: 0.8887\n",
      "Average recall_score score of the network: 0.8733\n",
      "Average precision_score score of the network: 0.9468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.85      0.49      0.62        35\n",
      "           3       0.69      0.48      0.57       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.82      0.74      0.78        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.93      0.36      0.52        77\n",
      "           9       0.96      0.52      0.68        44\n",
      "          10       0.82      0.56      0.67        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.58      0.73        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.96      0.42      0.58        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.97      0.70      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.79      0.85      1542\n",
      "   macro avg       0.84      0.63      0.71      1542\n",
      "weighted avg       0.92      0.79      0.84      1542\n",
      " samples avg       0.95      0.87      0.89      1542\n",
      "\n",
      "[2/  300] loss: 0.069\n",
      "Average F1 score of the network: 0.8881\n",
      "Average recall_score score of the network: 0.8611\n",
      "Average precision_score score of the network: 0.9602\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       1.00      0.46      0.63        35\n",
      "           3       0.82      0.38      0.52       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.97      0.38      0.54        77\n",
      "           9       0.96      0.52      0.68        44\n",
      "          10       0.96      0.50      0.66        48\n",
      "          11       0.79      0.85      0.81        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.74      0.82        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.90      0.34      0.49        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.97      0.70      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.95      0.77      0.85      1542\n",
      "   macro avg       0.86      0.63      0.71      1542\n",
      "weighted avg       0.95      0.77      0.83      1542\n",
      " samples avg       0.96      0.86      0.89      1542\n",
      "\n",
      "[2/  400] loss: 0.064\n",
      "Average F1 score of the network: 0.8868\n",
      "Average recall_score score of the network: 0.8708\n",
      "Average precision_score score of the network: 0.9471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.92      0.95       761\n",
      "           2       0.85      0.49      0.62        35\n",
      "           3       0.78      0.47      0.59       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.93      1.00      0.96        39\n",
      "           8       0.94      0.43      0.59        77\n",
      "           9       0.73      0.75      0.74        44\n",
      "          10       0.84      0.54      0.66        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.79      0.42      0.54        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.90      0.82      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.79      0.86      1542\n",
      "   macro avg       0.82      0.65      0.71      1542\n",
      "weighted avg       0.93      0.79      0.84      1542\n",
      " samples avg       0.95      0.87      0.89      1542\n",
      "\n",
      "[2/  500] loss: 0.065\n",
      "Average F1 score of the network: 0.8956\n",
      "Average recall_score score of the network: 0.8715\n",
      "Average precision_score score of the network: 0.9626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       1.00      0.49      0.65        35\n",
      "           3       0.81      0.44      0.57       153\n",
      "           4       1.00      0.67      0.80        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.74      0.85        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.89      0.44      0.59        77\n",
      "           9       0.91      0.68      0.78        44\n",
      "          10       0.86      0.52      0.65        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.58      0.73        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.88      0.40      0.55        53\n",
      "          16       0.93      0.93      0.93        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.95      0.79      0.86      1542\n",
      "   macro avg       0.85      0.64      0.72      1542\n",
      "weighted avg       0.94      0.79      0.85      1542\n",
      " samples avg       0.96      0.87      0.90      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8956039682539683 \n",
      "\n",
      "[2/  600] loss: 0.065\n",
      "Average F1 score of the network: 0.8902\n",
      "Average recall_score score of the network: 0.8728\n",
      "Average precision_score score of the network: 0.9507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       1.00      0.43      0.60        35\n",
      "           3       0.79      0.44      0.56       153\n",
      "           4       0.86      0.74      0.79        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.96      0.71      0.82        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.74      0.52      0.61        77\n",
      "           9       0.94      0.75      0.84        44\n",
      "          10       0.86      0.52      0.65        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.90      0.36      0.51        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       1.00      0.92      0.96        52\n",
      "\n",
      "   micro avg       0.94      0.80      0.86      1542\n",
      "   macro avg       0.84      0.64      0.72      1542\n",
      "weighted avg       0.93      0.80      0.85      1542\n",
      " samples avg       0.95      0.87      0.89      1542\n",
      "\n",
      "[2/  700] loss: 0.065\n",
      "Average F1 score of the network: 0.8933\n",
      "Average recall_score score of the network: 0.8682\n",
      "Average precision_score score of the network: 0.9587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.89      0.49      0.63        35\n",
      "           3       0.76      0.47      0.58       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.94      0.79      0.86        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.90      0.45      0.60        77\n",
      "           9       0.96      0.57      0.71        44\n",
      "          10       0.96      0.52      0.68        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.58      0.73        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.90      0.36      0.51        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.95      0.79      0.86      1542\n",
      "   macro avg       0.85      0.64      0.72      1542\n",
      "weighted avg       0.94      0.79      0.85      1542\n",
      " samples avg       0.96      0.87      0.89      1542\n",
      "\n",
      "[2/  800] loss: 0.066\n",
      "Average F1 score of the network: 0.8877\n",
      "Average recall_score score of the network: 0.8689\n",
      "Average precision_score score of the network: 0.9497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.94      0.49      0.64        35\n",
      "           3       0.77      0.42      0.54       153\n",
      "           4       1.00      0.71      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.87      0.43      0.57        77\n",
      "           9       0.96      0.55      0.70        44\n",
      "          10       0.87      0.54      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.88      0.28      0.43        53\n",
      "          16       0.89      0.93      0.91        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.97      0.80      0.88        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.79      0.85      1542\n",
      "   macro avg       0.84      0.64      0.71      1542\n",
      "weighted avg       0.92      0.79      0.83      1542\n",
      " samples avg       0.95      0.87      0.89      1542\n",
      "\n",
      "[2/  900] loss: 0.064\n",
      "Average F1 score of the network: 0.8890\n",
      "Average recall_score score of the network: 0.8800\n",
      "Average precision_score score of the network: 0.9387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.70      0.51      0.59       153\n",
      "           4       0.94      0.71      0.81        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.85      0.52      0.65        77\n",
      "           9       0.97      0.64      0.77        44\n",
      "          10       0.72      0.60      0.66        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.58      0.73        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.78      0.40      0.53        53\n",
      "          16       0.89      0.93      0.91        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.81      0.86      1542\n",
      "   macro avg       0.82      0.64      0.71      1542\n",
      "weighted avg       0.91      0.81      0.85      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[2/ 1000] loss: 0.070\n",
      "Average F1 score of the network: 0.8834\n",
      "Average recall_score score of the network: 0.8588\n",
      "Average precision_score score of the network: 0.9535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.98      0.91      0.94       761\n",
      "           2       0.94      0.49      0.64        35\n",
      "           3       0.77      0.40      0.53       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.89      0.51      0.64        77\n",
      "           9       0.96      0.59      0.73        44\n",
      "          10       0.77      0.50      0.61        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.95      0.36      0.52        53\n",
      "          16       0.86      0.93      0.89        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.97      0.80      0.88        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.95      0.77      0.85      1542\n",
      "   macro avg       0.83      0.64      0.71      1542\n",
      "weighted avg       0.94      0.77      0.84      1542\n",
      " samples avg       0.95      0.86      0.88      1542\n",
      "\n",
      "[2/ 1100] loss: 0.067\n",
      "Average F1 score of the network: 0.8928\n",
      "Average recall_score score of the network: 0.8791\n",
      "Average precision_score score of the network: 0.9482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.73      0.48      0.58       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.66      0.79        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.84      0.53      0.65        77\n",
      "           9       0.89      0.73      0.80        44\n",
      "          10       0.76      0.58      0.66        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.58      0.73        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.95      0.36      0.52        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.95      0.80      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.80      0.86      1542\n",
      "   macro avg       0.84      0.65      0.72      1542\n",
      "weighted avg       0.92      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[2/ 1200] loss: 0.068\n",
      "Average F1 score of the network: 0.8867\n",
      "Average recall_score score of the network: 0.8672\n",
      "Average precision_score score of the network: 0.9501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.92      0.95       761\n",
      "           2       0.94      0.46      0.62        35\n",
      "           3       0.69      0.44      0.54       153\n",
      "           4       0.85      0.79      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.83      0.51      0.63        77\n",
      "           9       0.91      0.68      0.78        44\n",
      "          10       0.76      0.54      0.63        48\n",
      "          11       0.91      0.77      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.95      0.40      0.56        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       1.00      0.70      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.79      0.85      1542\n",
      "   macro avg       0.83      0.64      0.72      1542\n",
      "weighted avg       0.92      0.79      0.84      1542\n",
      " samples avg       0.95      0.87      0.89      1542\n",
      "\n",
      "[2/ 1300] loss: 0.065\n",
      "Average F1 score of the network: 0.8850\n",
      "Average recall_score score of the network: 0.8609\n",
      "Average precision_score score of the network: 0.9546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.93      0.95       761\n",
      "           2       1.00      0.46      0.63        35\n",
      "           3       0.75      0.40      0.52       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.84      0.48      0.61        77\n",
      "           9       0.96      0.55      0.70        44\n",
      "          10       0.82      0.56      0.67        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.58      0.73        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.95      0.40      0.56        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.97      0.68      0.80        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.95      0.78      0.85      1542\n",
      "   macro avg       0.85      0.63      0.71      1542\n",
      "weighted avg       0.94      0.78      0.84      1542\n",
      " samples avg       0.95      0.86      0.88      1542\n",
      "\n",
      "[2/ 1400] loss: 0.065\n",
      "Average F1 score of the network: 0.8923\n",
      "Average recall_score score of the network: 0.8676\n",
      "Average precision_score score of the network: 0.9605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.98      0.93      0.95       761\n",
      "           2       0.94      0.46      0.62        35\n",
      "           3       0.73      0.49      0.59       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.92      0.44      0.60        77\n",
      "           9       0.94      0.66      0.77        44\n",
      "          10       0.93      0.52      0.67        48\n",
      "          11       0.91      0.77      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.81      0.68      0.74        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.95      0.34      0.50        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.97      0.68      0.80        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.95      0.79      0.86      1542\n",
      "   macro avg       0.85      0.63      0.71      1542\n",
      "weighted avg       0.94      0.79      0.85      1542\n",
      " samples avg       0.96      0.87      0.89      1542\n",
      "\n",
      "[2/ 1500] loss: 0.066\n",
      "Average F1 score of the network: 0.8896\n",
      "Average recall_score score of the network: 0.8808\n",
      "Average precision_score score of the network: 0.9405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.95       761\n",
      "           2       0.94      0.46      0.62        35\n",
      "           3       0.66      0.55      0.60       153\n",
      "           4       0.97      0.69      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.82      0.42      0.55        77\n",
      "           9       0.81      0.77      0.79        44\n",
      "          10       0.76      0.58      0.66        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.63      0.42      0.50        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.80      0.86      1542\n",
      "   macro avg       0.81      0.65      0.71      1542\n",
      "weighted avg       0.91      0.80      0.85      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[2/ 1600] loss: 0.063\n",
      "Average F1 score of the network: 0.8940\n",
      "Average recall_score score of the network: 0.8685\n",
      "Average precision_score score of the network: 0.9646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       1.00      0.46      0.63        35\n",
      "           3       0.84      0.35      0.49       153\n",
      "           4       0.97      0.71      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       1.00      0.74      0.85        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.87      0.44      0.59        77\n",
      "           9       0.91      0.68      0.78        44\n",
      "          10       0.96      0.50      0.66        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.92      0.42      0.57        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.95      0.78      0.86      1542\n",
      "   macro avg       0.86      0.64      0.72      1542\n",
      "weighted avg       0.95      0.78      0.84      1542\n",
      " samples avg       0.96      0.87      0.89      1542\n",
      "\n",
      "[2/ 1700] loss: 0.067\n",
      "Average F1 score of the network: 0.8901\n",
      "Average recall_score score of the network: 0.8741\n",
      "Average precision_score score of the network: 0.9489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.95       761\n",
      "           2       0.81      0.49      0.61        35\n",
      "           3       0.66      0.42      0.52       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.83      0.49      0.62        77\n",
      "           9       0.91      0.68      0.78        44\n",
      "          10       1.00      0.50      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.88      0.40      0.55        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.88      0.82      0.85        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.93      0.79      0.86      1542\n",
      "   macro avg       0.82      0.65      0.72      1542\n",
      "weighted avg       0.92      0.79      0.84      1542\n",
      " samples avg       0.95      0.87      0.89      1542\n",
      "\n",
      "[2/ 1800] loss: 0.062\n",
      "Average F1 score of the network: 0.8879\n",
      "Average recall_score score of the network: 0.8622\n",
      "Average precision_score score of the network: 0.9594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.89      0.49      0.63        35\n",
      "           3       0.83      0.33      0.47       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.91      0.39      0.55        77\n",
      "           9       0.82      0.82      0.82        44\n",
      "          10       0.89      0.52      0.66        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.95      0.34      0.50        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       0.92      0.94      0.93        52\n",
      "\n",
      "   micro avg       0.95      0.78      0.85      1542\n",
      "   macro avg       0.84      0.64      0.71      1542\n",
      "weighted avg       0.94      0.78      0.83      1542\n",
      " samples avg       0.96      0.86      0.89      1542\n",
      "\n",
      "[3/  100] loss: 0.061\n",
      "Average F1 score of the network: 0.8951\n",
      "Average recall_score score of the network: 0.8835\n",
      "Average precision_score score of the network: 0.9458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.95       761\n",
      "           2       0.94      0.49      0.64        35\n",
      "           3       0.67      0.53      0.59       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.83      0.49      0.62        77\n",
      "           9       0.93      0.64      0.76        44\n",
      "          10       0.83      0.60      0.70        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.76      0.68      0.72        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.85      0.43      0.58        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.95      0.80      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.81      0.86      1542\n",
      "   macro avg       0.82      0.66      0.73      1542\n",
      "weighted avg       0.91      0.81      0.85      1542\n",
      " samples avg       0.95      0.88      0.90      1542\n",
      "\n",
      "[3/  200] loss: 0.056\n",
      "Average F1 score of the network: 0.8970\n",
      "Average recall_score score of the network: 0.8919\n",
      "Average precision_score score of the network: 0.9421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.96      0.95       761\n",
      "           2       0.89      0.49      0.63        35\n",
      "           3       0.66      0.56      0.61       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.93      0.71      0.81        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.78      0.51      0.61        77\n",
      "           9       0.92      0.75      0.83        44\n",
      "          10       0.80      0.58      0.67        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.88      0.42      0.56        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.93      0.95      0.94        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.82      0.67      0.73      1542\n",
      "weighted avg       0.91      0.82      0.86      1542\n",
      " samples avg       0.94      0.89      0.90      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.896979365079365 \n",
      "\n",
      "[3/  300] loss: 0.054\n",
      "Average F1 score of the network: 0.8919\n",
      "Average recall_score score of the network: 0.8782\n",
      "Average precision_score score of the network: 0.9473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.93      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.70      0.54      0.61       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.89      0.40      0.55        77\n",
      "           9       0.82      0.84      0.83        44\n",
      "          10       0.79      0.54      0.64        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.77      0.43      0.55        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.93      0.80      0.86      1542\n",
      "   macro avg       0.83      0.65      0.72      1542\n",
      "weighted avg       0.92      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[3/  400] loss: 0.056\n",
      "Average F1 score of the network: 0.8988\n",
      "Average recall_score score of the network: 0.8835\n",
      "Average precision_score score of the network: 0.9534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.94      0.49      0.64        35\n",
      "           3       0.71      0.54      0.61       153\n",
      "           4       1.00      0.71      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.76      0.87        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.86      0.47      0.61        77\n",
      "           9       0.94      0.75      0.84        44\n",
      "          10       0.87      0.54      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.91      0.38      0.53        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.98      0.91      0.94        55\n",
      "          18       0.97      0.80      0.88        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.93      0.81      0.87      1542\n",
      "   macro avg       0.84      0.66      0.73      1542\n",
      "weighted avg       0.93      0.81      0.86      1542\n",
      " samples avg       0.95      0.88      0.90      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8987813131313132 \n",
      "\n",
      "[3/  500] loss: 0.055\n",
      "Average F1 score of the network: 0.8923\n",
      "Average recall_score score of the network: 0.8765\n",
      "Average precision_score score of the network: 0.9480\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.85      0.49      0.62        35\n",
      "           3       0.70      0.50      0.58       153\n",
      "           4       0.97      0.76      0.85        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.92      0.43      0.58        77\n",
      "           9       0.92      0.80      0.85        44\n",
      "          10       0.67      0.67      0.67        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.76      0.36      0.49        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.97      0.80      0.88        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.80      0.86      1542\n",
      "   macro avg       0.82      0.67      0.72      1542\n",
      "weighted avg       0.92      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[3/  600] loss: 0.054\n",
      "Average F1 score of the network: 0.8901\n",
      "Average recall_score score of the network: 0.8621\n",
      "Average precision_score score of the network: 0.9626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.98      0.92      0.95       761\n",
      "           2       0.89      0.49      0.63        35\n",
      "           3       0.81      0.40      0.54       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.91      0.42      0.57        77\n",
      "           9       0.94      0.66      0.77        44\n",
      "          10       0.93      0.58      0.72        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.91      0.38      0.53        53\n",
      "          16       0.93      0.93      0.93        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.97      0.80      0.88        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.96      0.78      0.86      1542\n",
      "   macro avg       0.85      0.65      0.72      1542\n",
      "weighted avg       0.95      0.78      0.84      1542\n",
      " samples avg       0.96      0.86      0.89      1542\n",
      "\n",
      "[3/  700] loss: 0.060\n",
      "Average F1 score of the network: 0.8838\n",
      "Average recall_score score of the network: 0.8564\n",
      "Average precision_score score of the network: 0.9568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.98      0.90      0.94       761\n",
      "           2       1.00      0.46      0.63        35\n",
      "           3       0.81      0.39      0.52       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.96      0.71      0.82        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.82      0.53      0.65        77\n",
      "           9       1.00      0.75      0.86        44\n",
      "          10       0.78      0.60      0.68        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.94      0.32      0.48        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       1.00      0.73      0.84        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.96      0.77      0.85      1542\n",
      "   macro avg       0.85      0.65      0.72      1542\n",
      "weighted avg       0.95      0.77      0.84      1542\n",
      " samples avg       0.96      0.86      0.88      1542\n",
      "\n",
      "[3/  800] loss: 0.058\n",
      "Average F1 score of the network: 0.8925\n",
      "Average recall_score score of the network: 0.8774\n",
      "Average precision_score score of the network: 0.9480\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.94      0.46      0.62        35\n",
      "           3       0.74      0.49      0.59       153\n",
      "           4       1.00      0.71      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.96      0.66      0.78        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.88      0.49      0.63        77\n",
      "           9       0.96      0.59      0.73        44\n",
      "          10       0.79      0.54      0.64        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.42      0.59        12\n",
      "          15       0.92      0.45      0.61        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.77      0.82      0.79        44\n",
      "          19       1.00      0.92      0.96        52\n",
      "\n",
      "   micro avg       0.93      0.80      0.86      1542\n",
      "   macro avg       0.83      0.65      0.71      1542\n",
      "weighted avg       0.92      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[3/  900] loss: 0.056\n",
      "Average F1 score of the network: 0.8929\n",
      "Average recall_score score of the network: 0.8918\n",
      "Average precision_score score of the network: 0.9353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.92      0.97      0.95       761\n",
      "           2       0.75      0.51      0.61        35\n",
      "           3       0.64      0.59      0.61       153\n",
      "           4       0.83      0.71      0.77        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.90      0.74      0.81        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.89      0.43      0.58        77\n",
      "           9       0.94      0.75      0.84        44\n",
      "          10       0.96      0.50      0.66        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.91      0.38      0.53        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.90      0.80      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.82      0.66      0.72      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[3/ 1000] loss: 0.057\n",
      "Average F1 score of the network: 0.8958\n",
      "Average recall_score score of the network: 0.8852\n",
      "Average precision_score score of the network: 0.9477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.89      0.49      0.63        35\n",
      "           3       0.74      0.51      0.60       153\n",
      "           4       0.97      0.69      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.66      0.79        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.75      0.55      0.63        77\n",
      "           9       0.88      0.86      0.87        44\n",
      "          10       0.93      0.52      0.67        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.91      0.38      0.53        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.92      0.80      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.81      0.86      1542\n",
      "   macro avg       0.83      0.66      0.73      1542\n",
      "weighted avg       0.92      0.81      0.85      1542\n",
      " samples avg       0.95      0.89      0.90      1542\n",
      "\n",
      "[3/ 1100] loss: 0.060\n",
      "Average F1 score of the network: 0.8962\n",
      "Average recall_score score of the network: 0.8852\n",
      "Average precision_score score of the network: 0.9473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.93      0.95       761\n",
      "           2       1.00      0.46      0.63        35\n",
      "           3       0.74      0.55      0.63       153\n",
      "           4       0.97      0.71      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.88      0.49      0.63        77\n",
      "           9       0.94      0.70      0.81        44\n",
      "          10       0.64      0.67      0.65        48\n",
      "          11       0.75      0.92      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.77      0.45      0.57        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.88      0.82      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.81      0.86      1542\n",
      "   macro avg       0.82      0.67      0.73      1542\n",
      "weighted avg       0.92      0.81      0.85      1542\n",
      " samples avg       0.95      0.89      0.90      1542\n",
      "\n",
      "[3/ 1200] loss: 0.057\n",
      "Average F1 score of the network: 0.8988\n",
      "Average recall_score score of the network: 0.8874\n",
      "Average precision_score score of the network: 0.9489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.94      0.49      0.64        35\n",
      "           3       0.71      0.56      0.62       153\n",
      "           4       0.89      0.74      0.81        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.80      0.74      0.77        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.88      0.49      0.63        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.76      0.60      0.67        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.95      0.36      0.52        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.82      0.86      1542\n",
      "   macro avg       0.82      0.67      0.72      1542\n",
      "weighted avg       0.91      0.82      0.85      1542\n",
      " samples avg       0.95      0.89      0.90      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8988365079365079 \n",
      "\n",
      "[3/ 1300] loss: 0.057\n",
      "Average F1 score of the network: 0.8955\n",
      "Average recall_score score of the network: 0.8751\n",
      "Average precision_score score of the network: 0.9581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.96       761\n",
      "           2       0.74      0.49      0.59        35\n",
      "           3       0.79      0.40      0.53       153\n",
      "           4       0.94      0.76      0.84        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.91      0.76      0.83        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.91      0.42      0.57        77\n",
      "           9       0.97      0.66      0.78        44\n",
      "          10       0.87      0.54      0.67        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.85      0.42      0.56        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.98      0.91      0.94        55\n",
      "          18       0.94      0.73      0.82        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.94      0.79      0.86      1542\n",
      "   macro avg       0.82      0.65      0.71      1542\n",
      "weighted avg       0.93      0.79      0.84      1542\n",
      " samples avg       0.96      0.88      0.90      1542\n",
      "\n",
      "[3/ 1400] loss: 0.056\n",
      "Average F1 score of the network: 0.8944\n",
      "Average recall_score score of the network: 0.8882\n",
      "Average precision_score score of the network: 0.9390\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.89      0.49      0.63        35\n",
      "           3       0.62      0.63      0.63       153\n",
      "           4       0.91      0.71      0.80        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.74      0.85        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.90      0.45      0.60        77\n",
      "           9       0.89      0.75      0.81        44\n",
      "          10       0.67      0.58      0.62        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.95      0.34      0.50        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.83      0.67      0.73      1542\n",
      "weighted avg       0.91      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[3/ 1500] loss: 0.058\n",
      "Average F1 score of the network: 0.8955\n",
      "Average recall_score score of the network: 0.8809\n",
      "Average precision_score score of the network: 0.9504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.89      0.49      0.63        35\n",
      "           3       0.69      0.54      0.61       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.88      0.49      0.63        77\n",
      "           9       1.00      0.64      0.78        44\n",
      "          10       0.78      0.58      0.67        48\n",
      "          11       0.91      0.77      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.95      0.38      0.54        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       1.00      0.70      0.83        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.93      0.81      0.86      1542\n",
      "   macro avg       0.84      0.64      0.72      1542\n",
      "weighted avg       0.92      0.81      0.85      1542\n",
      " samples avg       0.95      0.88      0.90      1542\n",
      "\n",
      "[3/ 1600] loss: 0.057\n",
      "Average F1 score of the network: 0.8935\n",
      "Average recall_score score of the network: 0.8705\n",
      "Average precision_score score of the network: 0.9570\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.94      0.49      0.64        35\n",
      "           3       0.86      0.49      0.62       153\n",
      "           4       0.89      0.76      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.81      0.45      0.58        77\n",
      "           9       0.96      0.61      0.75        44\n",
      "          10       0.77      0.56      0.65        48\n",
      "          11       0.91      0.77      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.80      0.45      0.58        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       1.00      0.70      0.83        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.95      0.79      0.86      1542\n",
      "   macro avg       0.84      0.64      0.72      1542\n",
      "weighted avg       0.94      0.79      0.85      1542\n",
      " samples avg       0.96      0.87      0.89      1542\n",
      "\n",
      "[3/ 1700] loss: 0.061\n",
      "Average F1 score of the network: 0.8959\n",
      "Average recall_score score of the network: 0.8759\n",
      "Average precision_score score of the network: 0.9572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.86      0.54      0.67        35\n",
      "           3       0.84      0.50      0.63       153\n",
      "           4       0.91      0.76      0.83        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.88      0.48      0.62        77\n",
      "           9       0.93      0.64      0.76        44\n",
      "          10       0.80      0.58      0.67        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.90      0.34      0.49        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.93      0.93      0.93        55\n",
      "          18       0.94      0.73      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.95      0.80      0.87      1542\n",
      "   macro avg       0.84      0.66      0.73      1542\n",
      "weighted avg       0.94      0.80      0.85      1542\n",
      " samples avg       0.96      0.88      0.90      1542\n",
      "\n",
      "[3/ 1800] loss: 0.060\n",
      "Average F1 score of the network: 0.8914\n",
      "Average recall_score score of the network: 0.8761\n",
      "Average precision_score score of the network: 0.9477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.95       761\n",
      "           2       0.85      0.49      0.62        35\n",
      "           3       0.80      0.45      0.58       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.88      0.48      0.62        77\n",
      "           9       0.90      0.64      0.75        44\n",
      "          10       0.82      0.56      0.67        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.64      0.43      0.52        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.88      0.80      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.80      0.86      1542\n",
      "   macro avg       0.83      0.65      0.72      1542\n",
      "weighted avg       0.92      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[4/  100] loss: 0.043\n",
      "Average F1 score of the network: 0.8982\n",
      "Average recall_score score of the network: 0.8849\n",
      "Average precision_score score of the network: 0.9512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.77      0.52      0.62       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.70      0.58      0.64        77\n",
      "           9       0.94      0.68      0.79        44\n",
      "          10       0.80      0.58      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.85      0.42      0.56        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.96      0.93      0.94        55\n",
      "          18       0.94      0.75      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.81      0.87      1542\n",
      "   macro avg       0.83      0.66      0.73      1542\n",
      "weighted avg       0.92      0.81      0.85      1542\n",
      " samples avg       0.95      0.88      0.90      1542\n",
      "\n",
      "[4/  200] loss: 0.047\n",
      "Average F1 score of the network: 0.8873\n",
      "Average recall_score score of the network: 0.8864\n",
      "Average precision_score score of the network: 0.9285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.94      0.49      0.64        35\n",
      "           3       0.60      0.59      0.59       153\n",
      "           4       1.00      0.71      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.74      0.85        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.77      0.52      0.62        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.76      0.60      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.70      0.40      0.51        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.98      0.84      0.90        55\n",
      "          18       0.90      0.80      0.84        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.82      0.67      0.73      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[4/  300] loss: 0.050\n",
      "Average F1 score of the network: 0.8937\n",
      "Average recall_score score of the network: 0.8771\n",
      "Average precision_score score of the network: 0.9518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.98      0.92      0.95       761\n",
      "           2       0.81      0.49      0.61        35\n",
      "           3       0.80      0.52      0.63       153\n",
      "           4       0.97      0.71      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.77      0.52      0.62        77\n",
      "           9       0.92      0.75      0.83        44\n",
      "          10       0.68      0.67      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.73      0.42      0.53        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.90      0.80      0.84        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.93      0.80      0.86      1542\n",
      "   macro avg       0.81      0.67      0.73      1542\n",
      "weighted avg       0.92      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[4/  400] loss: 0.048\n",
      "Average F1 score of the network: 0.8915\n",
      "Average recall_score score of the network: 0.8878\n",
      "Average precision_score score of the network: 0.9356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.96      0.95       761\n",
      "           2       0.67      0.57      0.62        35\n",
      "           3       0.77      0.47      0.58       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.86      0.42      0.56        77\n",
      "           9       0.86      0.73      0.79        44\n",
      "          10       0.76      0.60      0.67        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.50      0.47      0.49        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.93      0.91      0.92        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.81      0.86      1542\n",
      "   macro avg       0.80      0.67      0.72      1542\n",
      "weighted avg       0.90      0.81      0.84      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[4/  500] loss: 0.048\n",
      "Average F1 score of the network: 0.8947\n",
      "Average recall_score score of the network: 0.8810\n",
      "Average precision_score score of the network: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.81      0.49      0.61        35\n",
      "           3       0.72      0.51      0.60       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.61      0.75        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.77      0.52      0.62        77\n",
      "           9       0.96      0.61      0.75        44\n",
      "          10       0.74      0.58      0.65        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.84      0.40      0.54        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.95      0.80      0.86        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.93      0.80      0.86      1542\n",
      "   macro avg       0.82      0.66      0.72      1542\n",
      "weighted avg       0.92      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[4/  600] loss: 0.047\n",
      "Average F1 score of the network: 0.8952\n",
      "Average recall_score score of the network: 0.8877\n",
      "Average precision_score score of the network: 0.9410\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.89      0.49      0.63        35\n",
      "           3       0.68      0.58      0.62       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.94      0.76      0.84        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.70      0.55      0.61        77\n",
      "           9       0.97      0.64      0.77        44\n",
      "          10       0.72      0.69      0.70        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.82      0.43      0.57        53\n",
      "          16       0.86      0.93      0.89        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.82      0.66      0.72      1542\n",
      "weighted avg       0.91      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.90      1542\n",
      "\n",
      "[4/  700] loss: 0.047\n",
      "Average F1 score of the network: 0.8838\n",
      "Average recall_score score of the network: 0.8722\n",
      "Average precision_score score of the network: 0.9380\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.77      0.49      0.60        35\n",
      "           3       0.69      0.53      0.60       153\n",
      "           4       0.91      0.71      0.80        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.97      0.76      0.85        38\n",
      "           7       0.97      0.85      0.90        39\n",
      "           8       0.81      0.45      0.58        77\n",
      "           9       0.91      0.68      0.78        44\n",
      "          10       0.74      0.65      0.69        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.91      0.38      0.53        53\n",
      "          16       0.84      0.96      0.90        27\n",
      "          17       0.98      0.85      0.91        55\n",
      "          18       1.00      0.73      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.80      0.86      1542\n",
      "   macro avg       0.82      0.65      0.72      1542\n",
      "weighted avg       0.91      0.80      0.84      1542\n",
      " samples avg       0.94      0.87      0.88      1542\n",
      "\n",
      "[4/  800] loss: 0.049\n",
      "Average F1 score of the network: 0.8892\n",
      "Average recall_score score of the network: 0.8963\n",
      "Average precision_score score of the network: 0.9232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.96      0.95       761\n",
      "           2       0.80      0.46      0.58        35\n",
      "           3       0.60      0.64      0.62       153\n",
      "           4       0.72      0.79      0.75        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.64      0.53      0.58        77\n",
      "           9       0.78      0.66      0.72        44\n",
      "          10       0.77      0.62      0.69        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.76      0.42      0.54        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.98      0.93      0.95        55\n",
      "          18       0.95      0.80      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.88      0.83      0.85      1542\n",
      "   macro avg       0.78      0.68      0.72      1542\n",
      "weighted avg       0.87      0.83      0.85      1542\n",
      " samples avg       0.92      0.90      0.89      1542\n",
      "\n",
      "[4/  900] loss: 0.052\n",
      "Average F1 score of the network: 0.8974\n",
      "Average recall_score score of the network: 0.8840\n",
      "Average precision_score score of the network: 0.9511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.95       761\n",
      "           2       0.72      0.51      0.60        35\n",
      "           3       0.77      0.52      0.62       153\n",
      "           4       0.94      0.71      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.77      0.57      0.66        77\n",
      "           9       0.89      0.75      0.81        44\n",
      "          10       0.78      0.58      0.67        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.73      0.45      0.56        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.97      0.73      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.81      0.87      1542\n",
      "   macro avg       0.82      0.67      0.73      1542\n",
      "weighted avg       0.92      0.81      0.86      1542\n",
      " samples avg       0.95      0.88      0.90      1542\n",
      "\n",
      "[4/ 1000] loss: 0.049\n",
      "Average F1 score of the network: 0.8983\n",
      "Average recall_score score of the network: 0.8862\n",
      "Average precision_score score of the network: 0.9487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.96      0.96       761\n",
      "           2       0.86      0.51      0.64        35\n",
      "           3       0.72      0.51      0.60       153\n",
      "           4       0.97      0.71      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.93      1.00      0.96        39\n",
      "           8       0.86      0.48      0.62        77\n",
      "           9       0.91      0.68      0.78        44\n",
      "          10       0.77      0.56      0.65        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.83      0.45      0.59        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.82      0.87      1542\n",
      "   macro avg       0.82      0.67      0.73      1542\n",
      "weighted avg       0.92      0.82      0.86      1542\n",
      " samples avg       0.95      0.89      0.90      1542\n",
      "\n",
      "[4/ 1100] loss: 0.054\n",
      "Average F1 score of the network: 0.8904\n",
      "Average recall_score score of the network: 0.8766\n",
      "Average precision_score score of the network: 0.9472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.79      0.48      0.60       153\n",
      "           4       0.91      0.74      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.93      1.00      0.96        39\n",
      "           8       0.76      0.44      0.56        77\n",
      "           9       0.94      0.66      0.77        44\n",
      "          10       0.79      0.56      0.66        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.64      0.40      0.49        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.96      0.93      0.94        55\n",
      "          18       0.84      0.84      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.80      0.86      1542\n",
      "   macro avg       0.81      0.65      0.71      1542\n",
      "weighted avg       0.91      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[4/ 1200] loss: 0.045\n",
      "Average F1 score of the network: 0.8932\n",
      "Average recall_score score of the network: 0.8779\n",
      "Average precision_score score of the network: 0.9483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.90      0.51      0.65        35\n",
      "           3       0.71      0.58      0.64       153\n",
      "           4       0.97      0.71      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.68      0.81        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.84      0.40      0.54        77\n",
      "           9       0.89      0.70      0.78        44\n",
      "          10       0.79      0.56      0.66        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.85      0.42      0.56        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.98      0.91      0.94        55\n",
      "          18       0.97      0.73      0.83        44\n",
      "          19       0.92      0.94      0.93        52\n",
      "\n",
      "   micro avg       0.93      0.80      0.86      1542\n",
      "   macro avg       0.82      0.66      0.72      1542\n",
      "weighted avg       0.92      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[4/ 1300] loss: 0.053\n",
      "Average F1 score of the network: 0.8921\n",
      "Average recall_score score of the network: 0.8788\n",
      "Average precision_score score of the network: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.68      0.50      0.58       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.93      1.00      0.96        39\n",
      "           8       0.86      0.47      0.61        77\n",
      "           9       0.97      0.66      0.78        44\n",
      "          10       0.77      0.56      0.65        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.73      0.45      0.56        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.92      0.75      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.80      0.86      1542\n",
      "   macro avg       0.81      0.66      0.72      1542\n",
      "weighted avg       0.91      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[4/ 1400] loss: 0.051\n",
      "Average F1 score of the network: 0.8971\n",
      "Average recall_score score of the network: 0.8825\n",
      "Average precision_score score of the network: 0.9510\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.95       761\n",
      "           2       0.77      0.49      0.60        35\n",
      "           3       0.68      0.54      0.60       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.92      0.44      0.60        77\n",
      "           9       0.94      0.77      0.85        44\n",
      "          10       0.86      0.52      0.65        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.88      0.43      0.58        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.94      0.93      0.94        55\n",
      "          18       0.97      0.73      0.83        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.93      0.81      0.86      1542\n",
      "   macro avg       0.83      0.66      0.72      1542\n",
      "weighted avg       0.92      0.81      0.85      1542\n",
      " samples avg       0.95      0.88      0.90      1542\n",
      "\n",
      "[4/ 1500] loss: 0.054\n",
      "Average F1 score of the network: 0.8936\n",
      "Average recall_score score of the network: 0.8829\n",
      "Average precision_score score of the network: 0.9440\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.77      0.49      0.60        35\n",
      "           3       0.70      0.61      0.65       153\n",
      "           4       0.97      0.71      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.94      0.76      0.84        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.94      0.42      0.58        77\n",
      "           9       0.97      0.68      0.80        44\n",
      "          10       0.82      0.56      0.67        48\n",
      "          11       0.83      0.77      0.80        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.88      0.42      0.56        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.97      0.70      0.82        44\n",
      "          19       1.00      0.90      0.95        52\n",
      "\n",
      "   micro avg       0.92      0.81      0.86      1542\n",
      "   macro avg       0.83      0.65      0.72      1542\n",
      "weighted avg       0.92      0.81      0.85      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[4/ 1600] loss: 0.054\n",
      "Average F1 score of the network: 0.8967\n",
      "Average recall_score score of the network: 0.8876\n",
      "Average precision_score score of the network: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.64      0.61      0.63       153\n",
      "           4       0.89      0.74      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.83      0.79      0.81        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.88      0.45      0.60        77\n",
      "           9       0.94      0.70      0.81        44\n",
      "          10       0.82      0.56      0.67        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.89      0.45      0.60        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.96      0.93      0.94        55\n",
      "          18       0.97      0.73      0.83        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.83      0.66      0.72      1542\n",
      "weighted avg       0.91      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.90      1542\n",
      "\n",
      "[4/ 1700] loss: 0.050\n",
      "Average F1 score of the network: 0.8878\n",
      "Average recall_score score of the network: 0.8800\n",
      "Average precision_score score of the network: 0.9379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.94      0.49      0.64        35\n",
      "           3       0.70      0.50      0.58       153\n",
      "           4       0.94      0.76      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.88      0.48      0.62        77\n",
      "           9       0.93      0.64      0.76        44\n",
      "          10       0.81      0.54      0.65        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.62      0.45      0.52        53\n",
      "          16       0.81      0.96      0.88        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.92      0.77      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.81      0.86      1542\n",
      "   macro avg       0.82      0.66      0.72      1542\n",
      "weighted avg       0.90      0.81      0.85      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[4/ 1800] loss: 0.049\n",
      "Average F1 score of the network: 0.8945\n",
      "Average recall_score score of the network: 0.8752\n",
      "Average precision_score score of the network: 0.9530\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.96      0.95       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.84      0.42      0.57       153\n",
      "           4       1.00      0.71      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.74      0.85        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.89      0.44      0.59        77\n",
      "           9       1.00      0.57      0.72        44\n",
      "          10       0.75      0.56      0.64        48\n",
      "          11       0.91      0.77      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.79      0.42      0.54        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.98      0.91      0.94        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.94      0.80      0.86      1542\n",
      "   macro avg       0.84      0.64      0.72      1542\n",
      "weighted avg       0.93      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[5/  100] loss: 0.037\n",
      "Average F1 score of the network: 0.8983\n",
      "Average recall_score score of the network: 0.8971\n",
      "Average precision_score score of the network: 0.9365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.95       761\n",
      "           2       0.74      0.49      0.59        35\n",
      "           3       0.63      0.67      0.65       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.81      0.51      0.62        77\n",
      "           9       0.88      0.80      0.83        44\n",
      "          10       0.74      0.58      0.65        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.75      0.45      0.56        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.94      0.73      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.83      0.86      1542\n",
      "   macro avg       0.80      0.67      0.72      1542\n",
      "weighted avg       0.90      0.83      0.86      1542\n",
      " samples avg       0.94      0.90      0.90      1542\n",
      "\n",
      "[5/  200] loss: 0.040\n",
      "Average F1 score of the network: 0.8931\n",
      "Average recall_score score of the network: 0.8878\n",
      "Average precision_score score of the network: 0.9390\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.96      0.95       761\n",
      "           2       0.80      0.46      0.58        35\n",
      "           3       0.68      0.53      0.60       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.78      0.55      0.64        77\n",
      "           9       0.89      0.77      0.83        44\n",
      "          10       0.77      0.56      0.65        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.77      0.43      0.55        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.85      0.75      0.80        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.81      0.66      0.72      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[5/  300] loss: 0.036\n",
      "Average F1 score of the network: 0.8924\n",
      "Average recall_score score of the network: 0.8789\n",
      "Average precision_score score of the network: 0.9463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.96      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.82      0.39      0.53       153\n",
      "           4       0.78      0.76      0.77        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.93      0.71      0.81        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.85      0.51      0.63        77\n",
      "           9       0.94      0.73      0.82        44\n",
      "          10       0.83      0.50      0.62        48\n",
      "          11       0.71      0.92      0.80        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.70      0.40      0.51        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.85      0.77      0.81        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.80      0.86      1542\n",
      "   macro avg       0.80      0.66      0.71      1542\n",
      "weighted avg       0.91      0.80      0.84      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[5/  400] loss: 0.039\n",
      "Average F1 score of the network: 0.8939\n",
      "Average recall_score score of the network: 0.8887\n",
      "Average precision_score score of the network: 0.9391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.85      0.49      0.62        35\n",
      "           3       0.71      0.58      0.64       153\n",
      "           4       0.94      0.76      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.65      0.53      0.59        77\n",
      "           9       0.91      0.70      0.79        44\n",
      "          10       0.70      0.54      0.61        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.72      0.49      0.58        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.94      0.75      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.79      0.68      0.72      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[5/  500] loss: 0.040\n",
      "Average F1 score of the network: 0.8938\n",
      "Average recall_score score of the network: 0.8878\n",
      "Average precision_score score of the network: 0.9406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.96      0.96       761\n",
      "           2       0.77      0.49      0.60        35\n",
      "           3       0.75      0.48      0.58       153\n",
      "           4       0.88      0.71      0.79        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.66      0.79        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.69      0.52      0.59        77\n",
      "           9       0.90      0.80      0.84        44\n",
      "          10       0.60      0.65      0.62        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.67      0.42      0.51        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.79      0.67      0.72      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[5/  600] loss: 0.037\n",
      "Average F1 score of the network: 0.8912\n",
      "Average recall_score score of the network: 0.8696\n",
      "Average precision_score score of the network: 0.9540\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.82      0.43      0.57       153\n",
      "           4       0.97      0.71      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.95      0.95      0.95        39\n",
      "           8       0.80      0.45      0.58        77\n",
      "           9       0.93      0.64      0.76        44\n",
      "          10       0.96      0.50      0.66        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.66      0.43      0.52        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.92      0.82      0.87        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.94      0.79      0.86      1542\n",
      "   macro avg       0.83      0.65      0.72      1542\n",
      "weighted avg       0.93      0.79      0.85      1542\n",
      " samples avg       0.95      0.87      0.89      1542\n",
      "\n",
      "[5/  700] loss: 0.042\n",
      "Average F1 score of the network: 0.8912\n",
      "Average recall_score score of the network: 0.8820\n",
      "Average precision_score score of the network: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.95      0.96       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.66      0.55      0.60       153\n",
      "           4       0.94      0.71      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.74      0.85        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.68      0.55      0.60        77\n",
      "           9       0.97      0.64      0.77        44\n",
      "          10       0.82      0.56      0.67        48\n",
      "          11       0.91      0.77      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.75      0.45      0.56        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.92      0.75      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.81      0.86      1542\n",
      "   macro avg       0.81      0.65      0.71      1542\n",
      "weighted avg       0.91      0.81      0.85      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[5/  800] loss: 0.042\n",
      "Average F1 score of the network: 0.8967\n",
      "Average recall_score score of the network: 0.8894\n",
      "Average precision_score score of the network: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.95       761\n",
      "           2       0.80      0.46      0.58        35\n",
      "           3       0.74      0.56      0.64       153\n",
      "           4       1.00      0.76      0.86        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.81      0.76      0.78        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.80      0.48      0.60        77\n",
      "           9       0.83      0.86      0.84        44\n",
      "          10       0.65      0.69      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.81      0.40      0.53        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.98      0.93      0.95        55\n",
      "          18       0.90      0.80      0.84        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.79      0.69      0.73      1542\n",
      "weighted avg       0.91      0.82      0.86      1542\n",
      " samples avg       0.94      0.89      0.90      1542\n",
      "\n",
      "[5/  900] loss: 0.043\n",
      "Average F1 score of the network: 0.8931\n",
      "Average recall_score score of the network: 0.8796\n",
      "Average precision_score score of the network: 0.9479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.80      0.46      0.58        35\n",
      "           3       0.78      0.48      0.59       153\n",
      "           4       0.91      0.74      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.88      0.45      0.60        77\n",
      "           9       0.96      0.61      0.75        44\n",
      "          10       0.77      0.56      0.65        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.88      0.58      0.70        12\n",
      "          15       0.75      0.45      0.56        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.93      0.80      0.86      1542\n",
      "   macro avg       0.82      0.65      0.72      1542\n",
      "weighted avg       0.91      0.80      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[5/ 1000] loss: 0.041\n",
      "Average F1 score of the network: 0.8955\n",
      "Average recall_score score of the network: 0.8891\n",
      "Average precision_score score of the network: 0.9423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.96       761\n",
      "           2       0.85      0.49      0.62        35\n",
      "           3       0.73      0.54      0.62       153\n",
      "           4       0.94      0.71      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.57      0.61      0.59        77\n",
      "           9       0.97      0.66      0.78        44\n",
      "          10       0.81      0.54      0.65        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.71      0.45      0.55        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       1.00      0.77      0.87        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.80      0.67      0.73      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.90      1542\n",
      "\n",
      "[5/ 1100] loss: 0.043\n",
      "Average F1 score of the network: 0.8911\n",
      "Average recall_score score of the network: 0.8861\n",
      "Average precision_score score of the network: 0.9393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.68      0.49      0.57        35\n",
      "           3       0.81      0.47      0.60       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.53      0.56      0.54        77\n",
      "           9       0.85      0.80      0.82        44\n",
      "          10       0.84      0.56      0.68        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.88      0.43      0.58        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.95      0.82      0.88        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.81      0.86      1542\n",
      "   macro avg       0.81      0.67      0.72      1542\n",
      "weighted avg       0.90      0.81      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[5/ 1200] loss: 0.043\n",
      "Average F1 score of the network: 0.8993\n",
      "Average recall_score score of the network: 0.8798\n",
      "Average precision_score score of the network: 0.9585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.98      0.93      0.95       761\n",
      "           2       0.75      0.51      0.61        35\n",
      "           3       0.80      0.52      0.63       153\n",
      "           4       0.97      0.69      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.90      0.74      0.81        38\n",
      "           7       0.97      0.92      0.95        39\n",
      "           8       0.83      0.44      0.58        77\n",
      "           9       0.97      0.73      0.83        44\n",
      "          10       0.84      0.56      0.68        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.75      0.86        12\n",
      "          15       0.88      0.42      0.56        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.94      0.93      0.94        55\n",
      "          18       0.95      0.80      0.86        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.94      0.80      0.87      1542\n",
      "   macro avg       0.82      0.67      0.73      1542\n",
      "weighted avg       0.93      0.80      0.86      1542\n",
      " samples avg       0.96      0.88      0.90      1542\n",
      "\n",
      "Finished predicting\n",
      "successfully saved to 'result.csv'\n",
      "Yet the Best epoch, saving result. BEST F1: 0.8993142857142857 \n",
      "\n",
      "[5/ 1300] loss: 0.039\n",
      "Average F1 score of the network: 0.8946\n",
      "Average recall_score score of the network: 0.8852\n",
      "Average precision_score score of the network: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.95       761\n",
      "           2       0.81      0.49      0.61        35\n",
      "           3       0.75      0.44      0.55       153\n",
      "           4       1.00      0.69      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.65      0.51      0.57        77\n",
      "           9       0.92      0.82      0.87        44\n",
      "          10       0.78      0.60      0.68        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.91      0.40      0.55        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.93      0.93      0.93        55\n",
      "          18       0.88      0.82      0.85        44\n",
      "          19       0.98      0.96      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.81      0.86      1542\n",
      "   macro avg       0.80      0.67      0.72      1542\n",
      "weighted avg       0.91      0.81      0.85      1542\n",
      " samples avg       0.95      0.89      0.89      1542\n",
      "\n",
      "[5/ 1400] loss: 0.041\n",
      "Average F1 score of the network: 0.8940\n",
      "Average recall_score score of the network: 0.8709\n",
      "Average precision_score score of the network: 0.9580\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.96       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.86      0.41      0.56       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.95      0.95      0.95        39\n",
      "           8       0.91      0.40      0.56        77\n",
      "           9       0.97      0.66      0.78        44\n",
      "          10       0.78      0.58      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       0.86      0.50      0.63        12\n",
      "          15       0.79      0.43      0.56        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.96      0.93      0.94        55\n",
      "          18       0.92      0.80      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.95      0.79      0.86      1542\n",
      "   macro avg       0.83      0.64      0.71      1542\n",
      "weighted avg       0.94      0.79      0.85      1542\n",
      " samples avg       0.96      0.87      0.89      1542\n",
      "\n",
      "[5/ 1500] loss: 0.042\n",
      "Average F1 score of the network: 0.8935\n",
      "Average recall_score score of the network: 0.8862\n",
      "Average precision_score score of the network: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.81      0.49      0.61        35\n",
      "           3       0.75      0.56      0.64       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.80      0.74      0.77        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.79      0.48      0.60        77\n",
      "           9       1.00      0.59      0.74        44\n",
      "          10       0.78      0.58      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       0.88      0.58      0.70        12\n",
      "          15       0.75      0.45      0.56        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.92      0.77      0.84        44\n",
      "          19       0.96      0.96      0.96        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.81      0.66      0.72      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[5/ 1600] loss: 0.043\n",
      "Average F1 score of the network: 0.8952\n",
      "Average recall_score score of the network: 0.8867\n",
      "Average precision_score score of the network: 0.9431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.95       761\n",
      "           2       0.83      0.57      0.68        35\n",
      "           3       0.64      0.59      0.62       153\n",
      "           4       0.86      0.74      0.79        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.80      0.74      0.77        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.76      0.40      0.53        77\n",
      "           9       0.97      0.64      0.77        44\n",
      "          10       0.83      0.60      0.70        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.58      0.73        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.78      0.47      0.59        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.93      0.93      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.81      0.67      0.72      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.90      1542\n",
      "\n",
      "[5/ 1700] loss: 0.038\n",
      "Average F1 score of the network: 0.8970\n",
      "Average recall_score score of the network: 0.8891\n",
      "Average precision_score score of the network: 0.9456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.80      0.46      0.58        35\n",
      "           3       0.73      0.58      0.65       153\n",
      "           4       0.91      0.74      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.87      0.71      0.78        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.76      0.49      0.60        77\n",
      "           9       0.85      0.75      0.80        44\n",
      "          10       0.72      0.60      0.66        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.88      0.58      0.70        12\n",
      "          15       0.85      0.42      0.56        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.80      0.66      0.72      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.95      0.89      0.90      1542\n",
      "\n",
      "[5/ 1800] loss: 0.040\n",
      "Average F1 score of the network: 0.8960\n",
      "Average recall_score score of the network: 0.8847\n",
      "Average precision_score score of the network: 0.9464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.95       761\n",
      "           2       0.86      0.51      0.64        35\n",
      "           3       0.68      0.57      0.62       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.87      0.44      0.59        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.70      0.65      0.67        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.42      0.59        12\n",
      "          15       0.75      0.45      0.56        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.81      0.86      1542\n",
      "   macro avg       0.81      0.66      0.72      1542\n",
      "weighted avg       0.91      0.81      0.85      1542\n",
      " samples avg       0.95      0.88      0.90      1542\n",
      "\n",
      "[6/  100] loss: 0.028\n",
      "Average F1 score of the network: 0.8957\n",
      "Average recall_score score of the network: 0.8854\n",
      "Average precision_score score of the network: 0.9477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.79      0.54      0.64        35\n",
      "           3       0.75      0.52      0.62       153\n",
      "           4       0.86      0.76      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.88      0.74      0.80        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.80      0.48      0.60        77\n",
      "           9       0.84      0.73      0.78        44\n",
      "          10       0.68      0.62      0.65        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.75      0.45      0.56        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.95      0.80      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.81      0.86      1542\n",
      "   macro avg       0.79      0.68      0.72      1542\n",
      "weighted avg       0.91      0.81      0.85      1542\n",
      " samples avg       0.95      0.89      0.90      1542\n",
      "\n",
      "[6/  200] loss: 0.027\n",
      "Average F1 score of the network: 0.8973\n",
      "Average recall_score score of the network: 0.8876\n",
      "Average precision_score score of the network: 0.9463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.94      0.46      0.62        35\n",
      "           3       0.70      0.58      0.63       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.90      0.74      0.81        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.81      0.44      0.57        77\n",
      "           9       0.97      0.73      0.83        44\n",
      "          10       0.72      0.54      0.62        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.69      0.47      0.56        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.95      0.80      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.82      0.86      1542\n",
      "   macro avg       0.81      0.68      0.73      1542\n",
      "weighted avg       0.91      0.82      0.85      1542\n",
      " samples avg       0.95      0.89      0.90      1542\n",
      "\n",
      "[6/  300] loss: 0.027\n",
      "Average F1 score of the network: 0.8922\n",
      "Average recall_score score of the network: 0.8856\n",
      "Average precision_score score of the network: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.71      0.57      0.63        35\n",
      "           3       0.71      0.58      0.64       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.89      1.00      0.94        39\n",
      "           8       0.81      0.49      0.61        77\n",
      "           9       0.85      0.75      0.80        44\n",
      "          10       0.79      0.56      0.66        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.56      0.51      0.53        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.93      0.94        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.81      0.86      1542\n",
      "   macro avg       0.79      0.68      0.72      1542\n",
      "weighted avg       0.90      0.81      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[6/  400] loss: 0.030\n",
      "Average F1 score of the network: 0.8949\n",
      "Average recall_score score of the network: 0.8837\n",
      "Average precision_score score of the network: 0.9463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.71      0.49      0.58        35\n",
      "           3       0.77      0.56      0.64       153\n",
      "           4       0.91      0.71      0.80        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.80      0.74      0.77        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.86      0.47      0.61        77\n",
      "           9       0.92      0.77      0.84        44\n",
      "          10       0.67      0.65      0.66        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.75      0.45      0.56        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.84      0.93      0.88        55\n",
      "          18       1.00      0.75      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.92      0.81      0.86      1542\n",
      "   macro avg       0.80      0.67      0.72      1542\n",
      "weighted avg       0.91      0.81      0.85      1542\n",
      " samples avg       0.95      0.88      0.89      1542\n",
      "\n",
      "[6/  500] loss: 0.028\n",
      "Average F1 score of the network: 0.8874\n",
      "Average recall_score score of the network: 0.8836\n",
      "Average precision_score score of the network: 0.9343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.95       761\n",
      "           2       0.80      0.46      0.58        35\n",
      "           3       0.69      0.49      0.57       153\n",
      "           4       0.94      0.71      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.74      0.74      0.74        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.66      0.53      0.59        77\n",
      "           9       0.83      0.77      0.80        44\n",
      "          10       0.72      0.58      0.64        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.63      0.49      0.55        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.81      0.85      1542\n",
      "   macro avg       0.77      0.68      0.72      1542\n",
      "weighted avg       0.89      0.81      0.85      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[6/  600] loss: 0.030\n",
      "Average F1 score of the network: 0.8953\n",
      "Average recall_score score of the network: 0.8933\n",
      "Average precision_score score of the network: 0.9379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.95       761\n",
      "           2       0.74      0.57      0.65        35\n",
      "           3       0.72      0.54      0.62       153\n",
      "           4       0.91      0.71      0.80        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.69      0.76      0.72        38\n",
      "           7       0.93      1.00      0.96        39\n",
      "           8       0.72      0.49      0.58        77\n",
      "           9       0.89      0.75      0.81        44\n",
      "          10       0.81      0.52      0.63        48\n",
      "          11       0.75      0.92      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.62      0.49      0.55        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.94      0.93      0.94        55\n",
      "          18       0.92      0.82      0.87        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.77      0.68      0.72      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.90      1542\n",
      "\n",
      "[6/  700] loss: 0.030\n",
      "Average F1 score of the network: 0.8968\n",
      "Average recall_score score of the network: 0.8927\n",
      "Average precision_score score of the network: 0.9400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.82      0.51      0.63        35\n",
      "           3       0.70      0.55      0.62       153\n",
      "           4       0.86      0.76      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.88      0.74      0.80        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.73      0.52      0.61        77\n",
      "           9       0.87      0.77      0.82        44\n",
      "          10       0.72      0.65      0.68        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.71      0.45      0.55        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.93      0.94        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.80      0.68      0.73      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.90      1542\n",
      "\n",
      "[6/  800] loss: 0.031\n",
      "Average F1 score of the network: 0.8921\n",
      "Average recall_score score of the network: 0.8824\n",
      "Average precision_score score of the network: 0.9425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.85      0.49      0.62        35\n",
      "           3       0.76      0.46      0.58       153\n",
      "           4       0.91      0.74      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.66      0.57      0.61        77\n",
      "           9       0.97      0.68      0.80        44\n",
      "          10       0.71      0.60      0.65        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.61      0.53      0.57        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.81      0.86      1542\n",
      "   macro avg       0.79      0.67      0.72      1542\n",
      "weighted avg       0.90      0.81      0.85      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[6/  900] loss: 0.030\n",
      "Average F1 score of the network: 0.8904\n",
      "Average recall_score score of the network: 0.8893\n",
      "Average precision_score score of the network: 0.9338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.89      0.49      0.63        35\n",
      "           3       0.69      0.57      0.62       153\n",
      "           4       0.84      0.74      0.78        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.71      0.52      0.60        77\n",
      "           9       0.94      0.73      0.82        44\n",
      "          10       0.72      0.54      0.62        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.62      0.40      0.48        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.96      0.98        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.80      0.67      0.73      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[6/ 1000] loss: 0.031\n",
      "Average F1 score of the network: 0.8946\n",
      "Average recall_score score of the network: 0.8942\n",
      "Average precision_score score of the network: 0.9380\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.59      0.54      0.57        35\n",
      "           3       0.67      0.58      0.62       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.84      0.48      0.61        77\n",
      "           9       0.92      0.77      0.84        44\n",
      "          10       0.78      0.52      0.62        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.65      0.45      0.53        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.87      0.77      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.78      0.68      0.72      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[6/ 1100] loss: 0.033\n",
      "Average F1 score of the network: 0.8936\n",
      "Average recall_score score of the network: 0.8924\n",
      "Average precision_score score of the network: 0.9337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.76      0.46      0.57        35\n",
      "           3       0.66      0.63      0.64       153\n",
      "           4       0.94      0.76      0.84        42\n",
      "           5       0.97      0.97      0.97        30\n",
      "           6       0.74      0.74      0.74        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.75      0.51      0.60        77\n",
      "           9       0.94      0.73      0.82        44\n",
      "          10       0.68      0.58      0.63        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.78      0.40      0.53        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.96      0.98        52\n",
      "\n",
      "   micro avg       0.90      0.83      0.86      1542\n",
      "   macro avg       0.80      0.68      0.72      1542\n",
      "weighted avg       0.89      0.83      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[6/ 1200] loss: 0.036\n",
      "Average F1 score of the network: 0.8842\n",
      "Average recall_score score of the network: 0.8803\n",
      "Average precision_score score of the network: 0.9311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.73      0.46      0.56        35\n",
      "           3       0.64      0.58      0.60       153\n",
      "           4       0.86      0.74      0.79        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.78      0.74      0.76        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.61      0.53      0.57        77\n",
      "           9       0.91      0.70      0.79        44\n",
      "          10       0.70      0.58      0.64        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.50      0.67        12\n",
      "          15       0.70      0.40      0.51        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.91      0.70      0.79        44\n",
      "          19       0.98      0.96      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.81      0.85      1542\n",
      "   macro avg       0.78      0.66      0.71      1542\n",
      "weighted avg       0.89      0.81      0.84      1542\n",
      " samples avg       0.93      0.88      0.88      1542\n",
      "\n",
      "[6/ 1300] loss: 0.032\n",
      "Average F1 score of the network: 0.8902\n",
      "Average recall_score score of the network: 0.8887\n",
      "Average precision_score score of the network: 0.9328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.96      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.64      0.61      0.62       153\n",
      "           4       0.89      0.76      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      0.71      0.83        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.74      0.48      0.58        77\n",
      "           9       0.97      0.64      0.77        44\n",
      "          10       0.83      0.50      0.62        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.68      0.43      0.53        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.85      0.80      0.82        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.80      0.66      0.71      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[6/ 1400] loss: 0.035\n",
      "Average F1 score of the network: 0.8890\n",
      "Average recall_score score of the network: 0.8892\n",
      "Average precision_score score of the network: 0.9306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.96      0.95       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.68      0.53      0.60       153\n",
      "           4       0.94      0.76      0.84        42\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.67      0.48      0.56        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.79      0.56      0.66        48\n",
      "          11       0.67      0.92      0.77        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.57      0.45      0.51        53\n",
      "          16       0.89      0.93      0.91        27\n",
      "          17       0.94      0.93      0.94        55\n",
      "          18       0.94      0.75      0.84        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.77      0.67      0.71      1542\n",
      "weighted avg       0.88      0.82      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[6/ 1500] loss: 0.032\n",
      "Average F1 score of the network: 0.8869\n",
      "Average recall_score score of the network: 0.8880\n",
      "Average precision_score score of the network: 0.9288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.65      0.56      0.60       153\n",
      "           4       0.97      0.71      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.51      0.52      0.52        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.74      0.58      0.65        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.60      0.49      0.54        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.95      0.80      0.86        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.77      0.67      0.71      1542\n",
      "weighted avg       0.88      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[6/ 1600] loss: 0.031\n",
      "Average F1 score of the network: 0.8898\n",
      "Average recall_score score of the network: 0.8904\n",
      "Average precision_score score of the network: 0.9309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.96      0.96       761\n",
      "           2       0.77      0.49      0.60        35\n",
      "           3       0.66      0.60      0.63       153\n",
      "           4       0.86      0.74      0.79        42\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       0.82      0.74      0.78        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.66      0.48      0.56        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.76      0.52      0.62        48\n",
      "          11       0.91      0.77      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.81      0.68      0.74        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.65      0.38      0.48        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.86      1542\n",
      "   macro avg       0.78      0.66      0.71      1542\n",
      "weighted avg       0.88      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[6/ 1700] loss: 0.034\n",
      "Average F1 score of the network: 0.8909\n",
      "Average recall_score score of the network: 0.8955\n",
      "Average precision_score score of the network: 0.9259\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.96      0.95       761\n",
      "           2       0.81      0.49      0.61        35\n",
      "           3       0.65      0.61      0.63       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.90      0.74      0.81        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.65      0.47      0.55        77\n",
      "           9       0.94      0.73      0.82        44\n",
      "          10       0.76      0.65      0.70        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.64      0.47      0.54        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.82      0.75      0.79        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.88      0.83      0.86      1542\n",
      "   macro avg       0.78      0.68      0.72      1542\n",
      "weighted avg       0.88      0.83      0.85      1542\n",
      " samples avg       0.93      0.90      0.89      1542\n",
      "\n",
      "[6/ 1800] loss: 0.034\n",
      "Average F1 score of the network: 0.8860\n",
      "Average recall_score score of the network: 0.8868\n",
      "Average precision_score score of the network: 0.9293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.73      0.54      0.62        35\n",
      "           3       0.71      0.47      0.56       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.78      0.76      0.77        38\n",
      "           7       0.97      0.92      0.95        39\n",
      "           8       0.59      0.55      0.57        77\n",
      "           9       0.94      0.66      0.77        44\n",
      "          10       0.70      0.67      0.68        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       1.00      0.75      0.86        12\n",
      "          15       0.71      0.45      0.55        53\n",
      "          16       0.84      0.96      0.90        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.90      0.80      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.77      0.68      0.72      1542\n",
      "weighted avg       0.88      0.82      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[7/  100] loss: 0.020\n",
      "Average F1 score of the network: 0.8861\n",
      "Average recall_score score of the network: 0.8806\n",
      "Average precision_score score of the network: 0.9342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.70      0.46      0.55        35\n",
      "           3       0.71      0.55      0.62       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.96      0.87      0.91        30\n",
      "           6       0.76      0.74      0.75        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.73      0.47      0.57        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.66      0.69      0.67        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.54      0.49      0.51        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.81      0.85      1542\n",
      "   macro avg       0.77      0.67      0.72      1542\n",
      "weighted avg       0.90      0.81      0.85      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[7/  200] loss: 0.020\n",
      "Average F1 score of the network: 0.8927\n",
      "Average recall_score score of the network: 0.8862\n",
      "Average precision_score score of the network: 0.9392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.96      0.96       761\n",
      "           2       0.72      0.51      0.60        35\n",
      "           3       0.72      0.53      0.61       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.82      0.74      0.78        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.79      0.48      0.60        77\n",
      "           9       1.00      0.70      0.83        44\n",
      "          10       0.71      0.62      0.67        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.62      0.45      0.52        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.98      0.87      0.92        55\n",
      "          18       0.92      0.80      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.79      0.67      0.72      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[7/  300] loss: 0.019\n",
      "Average F1 score of the network: 0.8906\n",
      "Average recall_score score of the network: 0.8825\n",
      "Average precision_score score of the network: 0.9413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.96       761\n",
      "           2       0.76      0.46      0.57        35\n",
      "           3       0.67      0.53      0.59       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.74      0.44      0.55        77\n",
      "           9       0.89      0.75      0.81        44\n",
      "          10       0.74      0.54      0.63        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.63      0.49      0.55        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.91      0.95      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.81      0.86      1542\n",
      "   macro avg       0.79      0.66      0.72      1542\n",
      "weighted avg       0.90      0.81      0.85      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[7/  400] loss: 0.021\n",
      "Average F1 score of the network: 0.8891\n",
      "Average recall_score score of the network: 0.8940\n",
      "Average precision_score score of the network: 0.9245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.95       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.63      0.63      0.63       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.96      0.87      0.91        30\n",
      "           6       0.82      0.74      0.78        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.66      0.49      0.56        77\n",
      "           9       1.00      0.70      0.83        44\n",
      "          10       0.62      0.65      0.63        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.56      0.43      0.49        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.88      0.83      0.85      1542\n",
      "   macro avg       0.78      0.67      0.72      1542\n",
      "weighted avg       0.88      0.83      0.85      1542\n",
      " samples avg       0.92      0.89      0.89      1542\n",
      "\n",
      "[7/  500] loss: 0.023\n",
      "Average F1 score of the network: 0.8947\n",
      "Average recall_score score of the network: 0.8910\n",
      "Average precision_score score of the network: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.95       761\n",
      "           2       0.74      0.49      0.59        35\n",
      "           3       0.80      0.50      0.62       153\n",
      "           4       0.97      0.71      0.82        42\n",
      "           5       0.88      0.97      0.92        30\n",
      "           6       0.90      0.74      0.81        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.72      0.49      0.58        77\n",
      "           9       0.97      0.77      0.86        44\n",
      "          10       0.71      0.62      0.67        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.55      0.51      0.53        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.92      0.82      0.87        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.79      0.68      0.72      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[7/  600] loss: 0.025\n",
      "Average F1 score of the network: 0.8950\n",
      "Average recall_score score of the network: 0.8879\n",
      "Average precision_score score of the network: 0.9418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.75      0.47      0.58       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.62      0.49      0.55        77\n",
      "           9       0.94      0.77      0.85        44\n",
      "          10       0.71      0.56      0.63        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.67      0.49      0.57        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.97      0.84      0.90        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.80      0.67      0.73      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.90      1542\n",
      "\n",
      "[7/  700] loss: 0.023\n",
      "Average F1 score of the network: 0.8897\n",
      "Average recall_score score of the network: 0.8891\n",
      "Average precision_score score of the network: 0.9319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.96      0.95       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.75      0.47      0.58       153\n",
      "           4       0.84      0.76      0.80        42\n",
      "           5       0.96      0.87      0.91        30\n",
      "           6       0.90      0.74      0.81        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.63      0.55      0.58        77\n",
      "           9       0.92      0.77      0.84        44\n",
      "          10       0.71      0.60      0.65        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.65      0.45      0.53        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.92      0.80      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.79      0.67      0.72      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[7/  800] loss: 0.023\n",
      "Average F1 score of the network: 0.8892\n",
      "Average recall_score score of the network: 0.8886\n",
      "Average precision_score score of the network: 0.9324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.93      0.96      0.95       761\n",
      "           2       0.76      0.46      0.57        35\n",
      "           3       0.66      0.52      0.58       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.74      0.74      0.74        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.66      0.51      0.57        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.87      0.54      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.89      0.45      0.60        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.80      0.67      0.72      1542\n",
      "weighted avg       0.89      0.82      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[7/  900] loss: 0.023\n",
      "Average F1 score of the network: 0.8914\n",
      "Average recall_score score of the network: 0.8840\n",
      "Average precision_score score of the network: 0.9379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.82      0.51      0.63        35\n",
      "           3       0.78      0.45      0.57       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.82      0.74      0.78        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.88      0.45      0.60        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.63      0.65      0.64        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.57      0.49      0.53        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.92      0.80      0.85        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.91      0.81      0.86      1542\n",
      "   macro avg       0.79      0.68      0.72      1542\n",
      "weighted avg       0.90      0.81      0.85      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[7/ 1000] loss: 0.024\n",
      "Average F1 score of the network: 0.8907\n",
      "Average recall_score score of the network: 0.8841\n",
      "Average precision_score score of the network: 0.9399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.85      0.49      0.62        35\n",
      "           3       0.75      0.50      0.60       153\n",
      "           4       0.82      0.76      0.79        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.76      0.48      0.59        77\n",
      "           9       0.93      0.61      0.74        44\n",
      "          10       0.75      0.56      0.64        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.72      0.43      0.54        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.92      0.82      0.87        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.91      0.81      0.86      1542\n",
      "   macro avg       0.79      0.66      0.72      1542\n",
      "weighted avg       0.89      0.81      0.84      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[7/ 1100] loss: 0.023\n",
      "Average F1 score of the network: 0.8852\n",
      "Average recall_score score of the network: 0.8867\n",
      "Average precision_score score of the network: 0.9272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.76      0.54      0.63        35\n",
      "           3       0.60      0.56      0.58       153\n",
      "           4       0.97      0.71      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.69      0.45      0.55        77\n",
      "           9       0.86      0.68      0.76        44\n",
      "          10       0.69      0.56      0.62        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.73      0.42      0.53        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.84      0.84      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.78      0.67      0.72      1542\n",
      "weighted avg       0.88      0.82      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[7/ 1200] loss: 0.024\n",
      "Average F1 score of the network: 0.8951\n",
      "Average recall_score score of the network: 0.8941\n",
      "Average precision_score score of the network: 0.9369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.96       761\n",
      "           2       0.75      0.51      0.61        35\n",
      "           3       0.70      0.58      0.63       153\n",
      "           4       0.91      0.76      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.70      0.51      0.59        77\n",
      "           9       0.94      0.77      0.85        44\n",
      "          10       0.81      0.52      0.63        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.57      0.55      0.56        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.85      0.80      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.83      0.86      1542\n",
      "   macro avg       0.78      0.68      0.72      1542\n",
      "weighted avg       0.89      0.83      0.85      1542\n",
      " samples avg       0.94      0.89      0.90      1542\n",
      "\n",
      "[7/ 1300] loss: 0.023\n",
      "Average F1 score of the network: 0.8873\n",
      "Average recall_score score of the network: 0.8880\n",
      "Average precision_score score of the network: 0.9277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.96      0.95       761\n",
      "           2       0.74      0.49      0.59        35\n",
      "           3       0.68      0.57      0.62       153\n",
      "           4       0.80      0.76      0.78        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.88      0.74      0.80        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.65      0.48      0.55        77\n",
      "           9       0.97      0.68      0.80        44\n",
      "          10       0.84      0.56      0.68        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       0.80      0.67      0.73        12\n",
      "          15       0.70      0.43      0.53        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.92      0.80      0.85        44\n",
      "          19       1.00      0.92      0.96        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.78      0.67      0.71      1542\n",
      "weighted avg       0.88      0.82      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[7/ 1400] loss: 0.024\n",
      "Average F1 score of the network: 0.8910\n",
      "Average recall_score score of the network: 0.8855\n",
      "Average precision_score score of the network: 0.9354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.70      0.54      0.61        35\n",
      "           3       0.80      0.46      0.59       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.78      0.47      0.59        77\n",
      "           9       1.00      0.70      0.83        44\n",
      "          10       0.78      0.60      0.68        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.55      0.55      0.55        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.89      0.77      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.81      0.86      1542\n",
      "   macro avg       0.79      0.67      0.72      1542\n",
      "weighted avg       0.90      0.81      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[7/ 1500] loss: 0.024\n",
      "Average F1 score of the network: 0.8897\n",
      "Average recall_score score of the network: 0.8901\n",
      "Average precision_score score of the network: 0.9301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.65      0.61      0.63       153\n",
      "           4       1.00      0.71      0.83        42\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       0.90      0.74      0.81        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.71      0.45      0.56        77\n",
      "           9       0.92      0.77      0.84        44\n",
      "          10       0.64      0.58      0.61        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.76      0.47      0.58        53\n",
      "          16       0.76      0.96      0.85        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.90      0.80      0.84        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.78      0.67      0.71      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[7/ 1600] loss: 0.027\n",
      "Average F1 score of the network: 0.8931\n",
      "Average recall_score score of the network: 0.8880\n",
      "Average precision_score score of the network: 0.9369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.95      0.95       761\n",
      "           2       0.77      0.49      0.60        35\n",
      "           3       0.73      0.54      0.62       153\n",
      "           4       0.97      0.76      0.85        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.88      0.74      0.80        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.85      0.44      0.58        77\n",
      "           9       0.97      0.75      0.85        44\n",
      "          10       0.66      0.69      0.67        48\n",
      "          11       0.71      0.92      0.80        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.68      0.68      0.68        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.70      0.43      0.53        53\n",
      "          16       0.84      0.96      0.90        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.97      0.80      0.88        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.77      0.68      0.71      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[7/ 1700] loss: 0.025\n",
      "Average F1 score of the network: 0.8846\n",
      "Average recall_score score of the network: 0.8937\n",
      "Average precision_score score of the network: 0.9171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.93      0.96      0.95       761\n",
      "           2       0.77      0.49      0.60        35\n",
      "           3       0.66      0.58      0.62       153\n",
      "           4       0.86      0.76      0.81        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.70      0.74      0.72        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.60      0.51      0.55        77\n",
      "           9       0.94      0.77      0.85        44\n",
      "          10       0.60      0.67      0.63        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.61      0.43      0.51        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.94      0.87      0.91        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.87      0.83      0.85      1542\n",
      "   macro avg       0.76      0.68      0.71      1542\n",
      "weighted avg       0.86      0.83      0.84      1542\n",
      " samples avg       0.92      0.89      0.88      1542\n",
      "\n",
      "[7/ 1800] loss: 0.027\n",
      "Average F1 score of the network: 0.8871\n",
      "Average recall_score score of the network: 0.8847\n",
      "Average precision_score score of the network: 0.9308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.72      0.51      0.60        35\n",
      "           3       0.79      0.50      0.61       153\n",
      "           4       0.89      0.79      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.80      0.74      0.77        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.74      0.51      0.60        77\n",
      "           9       0.86      0.82      0.84        44\n",
      "          10       0.71      0.60      0.65        48\n",
      "          11       0.63      0.92      0.75        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.47      0.53      0.50        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.92      0.89      0.91        55\n",
      "          18       0.97      0.80      0.88        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.81      0.85      1542\n",
      "   macro avg       0.76      0.68      0.72      1542\n",
      "weighted avg       0.89      0.81      0.85      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[8/  100] loss: 0.014\n",
      "Average F1 score of the network: 0.8892\n",
      "Average recall_score score of the network: 0.8946\n",
      "Average precision_score score of the network: 0.9244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.71      0.49      0.58        35\n",
      "           3       0.65      0.58      0.62       153\n",
      "           4       0.80      0.79      0.80        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.97      0.74      0.84        38\n",
      "           7       1.00      0.97      0.99        39\n",
      "           8       0.75      0.51      0.60        77\n",
      "           9       0.92      0.82      0.87        44\n",
      "          10       0.68      0.62      0.65        48\n",
      "          11       0.75      0.92      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.51      0.53      0.52        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       1.00      0.88      0.94        52\n",
      "\n",
      "   micro avg       0.88      0.83      0.85      1542\n",
      "   macro avg       0.77      0.69      0.72      1542\n",
      "weighted avg       0.88      0.83      0.85      1542\n",
      " samples avg       0.92      0.89      0.89      1542\n",
      "\n",
      "[8/  200] loss: 0.015\n",
      "Average F1 score of the network: 0.8875\n",
      "Average recall_score score of the network: 0.8875\n",
      "Average precision_score score of the network: 0.9301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.95       761\n",
      "           2       0.73      0.54      0.62        35\n",
      "           3       0.70      0.56      0.62       153\n",
      "           4       0.94      0.76      0.84        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.69      0.53      0.60        77\n",
      "           9       0.94      0.68      0.79        44\n",
      "          10       0.62      0.62      0.62        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.65      0.68      0.67        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.66      0.43      0.52        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.94      0.77      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.77      0.67      0.71      1542\n",
      "weighted avg       0.88      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[8/  300] loss: 0.015\n",
      "Average F1 score of the network: 0.8862\n",
      "Average recall_score score of the network: 0.8806\n",
      "Average precision_score score of the network: 0.9334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.67      0.51      0.58        35\n",
      "           3       0.70      0.48      0.57       153\n",
      "           4       0.79      0.81      0.80        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.90      0.74      0.81        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.86      0.42      0.56        77\n",
      "           9       0.94      0.70      0.81        44\n",
      "          10       0.72      0.54      0.62        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.80      0.63      0.71        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.63      0.45      0.53        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.90      0.81      0.85      1542\n",
      "   macro avg       0.78      0.66      0.71      1542\n",
      "weighted avg       0.89      0.81      0.84      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[8/  400] loss: 0.014\n",
      "Average F1 score of the network: 0.8875\n",
      "Average recall_score score of the network: 0.8841\n",
      "Average precision_score score of the network: 0.9317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.95       761\n",
      "           2       0.75      0.51      0.61        35\n",
      "           3       0.70      0.52      0.60       153\n",
      "           4       0.94      0.76      0.84        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.90      0.74      0.81        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.65      0.55      0.59        77\n",
      "           9       0.97      0.66      0.78        44\n",
      "          10       0.70      0.54      0.61        48\n",
      "          11       0.75      0.92      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.76      0.47      0.58        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.82      0.84      0.83        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.89      0.81      0.85      1542\n",
      "   macro avg       0.77      0.67      0.72      1542\n",
      "weighted avg       0.89      0.81      0.84      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[8/  500] loss: 0.016\n",
      "Average F1 score of the network: 0.8867\n",
      "Average recall_score score of the network: 0.8856\n",
      "Average precision_score score of the network: 0.9310\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.67      0.46      0.55       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       0.88      0.74      0.80        38\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       0.64      0.56      0.60        77\n",
      "           9       0.85      0.77      0.81        44\n",
      "          10       0.65      0.65      0.65        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.75      0.86        12\n",
      "          15       0.71      0.47      0.57        53\n",
      "          16       0.93      0.93      0.93        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.92      0.75      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.81      0.85      1542\n",
      "   macro avg       0.79      0.68      0.72      1542\n",
      "weighted avg       0.88      0.81      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[8/  600] loss: 0.016\n",
      "Average F1 score of the network: 0.8866\n",
      "Average recall_score score of the network: 0.8839\n",
      "Average precision_score score of the network: 0.9317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.95       761\n",
      "           2       0.89      0.49      0.63        35\n",
      "           3       0.69      0.52      0.59       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.96      0.71      0.82        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.61      0.56      0.58        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.66      0.60      0.63        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.74      0.43      0.55        53\n",
      "          16       0.84      0.96      0.90        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.80      0.75      0.78        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.89      0.81      0.85      1542\n",
      "   macro avg       0.78      0.67      0.71      1542\n",
      "weighted avg       0.89      0.81      0.84      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[8/  700] loss: 0.016\n",
      "Average F1 score of the network: 0.8854\n",
      "Average recall_score score of the network: 0.8834\n",
      "Average precision_score score of the network: 0.9306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.93      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.71      0.53      0.61       153\n",
      "           4       0.84      0.76      0.80        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.90      0.71      0.79        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.65      0.53      0.59        77\n",
      "           9       0.89      0.73      0.80        44\n",
      "          10       0.68      0.58      0.63        48\n",
      "          11       0.67      0.92      0.77        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.57      0.53      0.55        53\n",
      "          16       0.93      0.93      0.93        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.91      0.73      0.81        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.81      0.85      1542\n",
      "   macro avg       0.77      0.68      0.71      1542\n",
      "weighted avg       0.89      0.81      0.85      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[8/  800] loss: 0.018\n",
      "Average F1 score of the network: 0.8848\n",
      "Average recall_score score of the network: 0.8896\n",
      "Average precision_score score of the network: 0.9233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.94      0.46      0.62        35\n",
      "           3       0.66      0.58      0.62       153\n",
      "           4       0.91      0.76      0.83        42\n",
      "           5       0.93      0.90      0.92        30\n",
      "           6       0.93      0.71      0.81        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.51      0.58      0.54        77\n",
      "           9       0.91      0.73      0.81        44\n",
      "          10       0.64      0.60      0.62        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.88      0.58      0.70        12\n",
      "          15       0.71      0.45      0.55        53\n",
      "          16       0.79      0.96      0.87        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.89      0.77      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.88      0.82      0.85      1542\n",
      "   macro avg       0.78      0.67      0.71      1542\n",
      "weighted avg       0.88      0.82      0.84      1542\n",
      " samples avg       0.92      0.89      0.88      1542\n",
      "\n",
      "[8/  900] loss: 0.017\n",
      "Average F1 score of the network: 0.8889\n",
      "Average recall_score score of the network: 0.8842\n",
      "Average precision_score score of the network: 0.9345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.92      0.95       761\n",
      "           2       0.82      0.51      0.63        35\n",
      "           3       0.70      0.58      0.63       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       0.76      0.74      0.75        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.63      0.53      0.58        77\n",
      "           9       0.85      0.77      0.81        44\n",
      "          10       0.62      0.52      0.57        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.88      0.58      0.70        12\n",
      "          15       0.83      0.47      0.60        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.95      0.82      0.88        44\n",
      "          19       0.96      0.96      0.96        52\n",
      "\n",
      "   micro avg       0.90      0.81      0.85      1542\n",
      "   macro avg       0.77      0.67      0.71      1542\n",
      "weighted avg       0.89      0.81      0.85      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[8/ 1000] loss: 0.016\n",
      "Average F1 score of the network: 0.8866\n",
      "Average recall_score score of the network: 0.8979\n",
      "Average precision_score score of the network: 0.9165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.69      0.51      0.59        35\n",
      "           3       0.67      0.63      0.65       153\n",
      "           4       0.79      0.81      0.80        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.76      0.74      0.75        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.60      0.53      0.57        77\n",
      "           9       0.94      0.70      0.81        44\n",
      "          10       0.63      0.54      0.58        48\n",
      "          11       0.79      0.85      0.81        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.88      0.58      0.70        12\n",
      "          15       0.54      0.51      0.52        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.92      0.80      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.87      0.83      0.85      1542\n",
      "   macro avg       0.75      0.67      0.71      1542\n",
      "weighted avg       0.86      0.83      0.85      1542\n",
      " samples avg       0.92      0.90      0.89      1542\n",
      "\n",
      "[8/ 1100] loss: 0.018\n",
      "Average F1 score of the network: 0.8833\n",
      "Average recall_score score of the network: 0.8915\n",
      "Average precision_score score of the network: 0.9155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.96      0.95       761\n",
      "           2       0.68      0.49      0.57        35\n",
      "           3       0.62      0.56      0.59       153\n",
      "           4       0.91      0.76      0.83        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.60      0.76      0.67        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.60      0.53      0.57        77\n",
      "           9       0.83      0.77      0.80        44\n",
      "          10       0.83      0.52      0.64        48\n",
      "          11       0.75      0.92      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.65      0.45      0.53        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.96      0.87      0.91        55\n",
      "          18       0.90      0.82      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.87      0.83      0.85      1542\n",
      "   macro avg       0.76      0.67      0.71      1542\n",
      "weighted avg       0.86      0.83      0.84      1542\n",
      " samples avg       0.92      0.89      0.88      1542\n",
      "\n",
      "[8/ 1200] loss: 0.017\n",
      "Average F1 score of the network: 0.8876\n",
      "Average recall_score score of the network: 0.8850\n",
      "Average precision_score score of the network: 0.9322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.93      0.96      0.94       761\n",
      "           2       0.77      0.49      0.60        35\n",
      "           3       0.80      0.46      0.58       153\n",
      "           4       0.89      0.79      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.77      0.47      0.58        77\n",
      "           9       1.00      0.66      0.79        44\n",
      "          10       0.78      0.58      0.67        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.57      0.47      0.52        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.96      0.87      0.91        55\n",
      "          18       0.89      0.77      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.81      0.85      1542\n",
      "   macro avg       0.79      0.67      0.71      1542\n",
      "weighted avg       0.89      0.81      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[8/ 1300] loss: 0.018\n",
      "Average F1 score of the network: 0.8892\n",
      "Average recall_score score of the network: 0.8791\n",
      "Average precision_score score of the network: 0.9393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.71      0.49      0.58        35\n",
      "           3       0.78      0.48      0.59       153\n",
      "           4       0.89      0.74      0.81        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.80      0.74      0.77        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.72      0.51      0.60        77\n",
      "           9       0.97      0.75      0.85        44\n",
      "          10       0.69      0.56      0.62        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.68      0.47      0.56        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.96      0.87      0.91        55\n",
      "          18       0.92      0.77      0.84        44\n",
      "          19       1.00      0.92      0.96        52\n",
      "\n",
      "   micro avg       0.91      0.81      0.85      1542\n",
      "   macro avg       0.78      0.67      0.72      1542\n",
      "weighted avg       0.90      0.81      0.84      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[8/ 1400] loss: 0.018\n",
      "Average F1 score of the network: 0.8822\n",
      "Average recall_score score of the network: 0.8795\n",
      "Average precision_score score of the network: 0.9286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.93      0.95       761\n",
      "           2       0.71      0.57      0.63        35\n",
      "           3       0.74      0.44      0.55       153\n",
      "           4       0.89      0.74      0.81        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.78      0.74      0.76        38\n",
      "           7       0.93      0.97      0.95        39\n",
      "           8       0.66      0.57      0.61        77\n",
      "           9       1.00      0.70      0.83        44\n",
      "          10       0.76      0.58      0.66        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.64      0.51      0.57        53\n",
      "          16       0.83      0.93      0.88        27\n",
      "          17       0.91      0.91      0.91        55\n",
      "          18       0.74      0.84      0.79        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.89      0.81      0.85      1542\n",
      "   macro avg       0.77      0.67      0.71      1542\n",
      "weighted avg       0.88      0.81      0.84      1542\n",
      " samples avg       0.93      0.88      0.88      1542\n",
      "\n",
      "[8/ 1500] loss: 0.019\n",
      "Average F1 score of the network: 0.8850\n",
      "Average recall_score score of the network: 0.8839\n",
      "Average precision_score score of the network: 0.9257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.95       761\n",
      "           2       0.69      0.51      0.59        35\n",
      "           3       0.74      0.49      0.59       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.80      0.74      0.77        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.69      0.49      0.58        77\n",
      "           9       0.85      0.75      0.80        44\n",
      "          10       0.62      0.60      0.61        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.80      0.67      0.73        12\n",
      "          15       0.64      0.51      0.57        53\n",
      "          16       1.00      0.93      0.96        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.73      0.82      0.77        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.81      0.85      1542\n",
      "   macro avg       0.75      0.68      0.71      1542\n",
      "weighted avg       0.88      0.81      0.84      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[8/ 1600] loss: 0.022\n",
      "Average F1 score of the network: 0.8923\n",
      "Average recall_score score of the network: 0.8902\n",
      "Average precision_score score of the network: 0.9346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.72      0.56      0.63       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.70      0.49      0.58        77\n",
      "           9       0.87      0.75      0.80        44\n",
      "          10       0.72      0.60      0.66        48\n",
      "          11       0.75      0.92      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.77      0.45      0.57        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.92      0.82      0.87        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.79      0.67      0.72      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[8/ 1700] loss: 0.021\n",
      "Average F1 score of the network: 0.8902\n",
      "Average recall_score score of the network: 0.8921\n",
      "Average precision_score score of the network: 0.9291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.82      0.51      0.63        35\n",
      "           3       0.65      0.59      0.62       153\n",
      "           4       0.91      0.74      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.82      0.74      0.78        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.68      0.53      0.60        77\n",
      "           9       0.92      0.75      0.83        44\n",
      "          10       0.70      0.65      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.62      0.49      0.55        53\n",
      "          16       0.93      0.93      0.93        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.90      0.82      0.86        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.78      0.69      0.73      1542\n",
      "weighted avg       0.88      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[8/ 1800] loss: 0.019\n",
      "Average F1 score of the network: 0.8884\n",
      "Average recall_score score of the network: 0.8905\n",
      "Average precision_score score of the network: 0.9267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.71      0.49      0.58        35\n",
      "           3       0.62      0.59      0.60       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.80      0.74      0.77        38\n",
      "           7       0.97      0.92      0.95        39\n",
      "           8       0.78      0.52      0.62        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.70      0.58      0.64        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.75      0.86        12\n",
      "          15       0.68      0.47      0.56        53\n",
      "          16       0.87      0.96      0.91        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.85      0.80      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.77      0.68      0.72      1542\n",
      "weighted avg       0.88      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[9/  100] loss: 0.012\n",
      "Average F1 score of the network: 0.8936\n",
      "Average recall_score score of the network: 0.8894\n",
      "Average precision_score score of the network: 0.9384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.75      0.51      0.61        35\n",
      "           3       0.70      0.58      0.63       153\n",
      "           4       0.89      0.74      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.87      0.71      0.78        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.75      0.51      0.60        77\n",
      "           9       0.94      0.73      0.82        44\n",
      "          10       0.64      0.58      0.61        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.68      0.53      0.60        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.87      0.77      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.78      0.68      0.72      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[9/  200] loss: 0.011\n",
      "Average F1 score of the network: 0.8880\n",
      "Average recall_score score of the network: 0.8881\n",
      "Average precision_score score of the network: 0.9289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.72      0.51      0.60        35\n",
      "           3       0.71      0.59      0.64       153\n",
      "           4       0.86      0.74      0.79        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.74      0.74      0.74        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.73      0.49      0.59        77\n",
      "           9       1.00      0.66      0.79        44\n",
      "          10       0.75      0.50      0.60        48\n",
      "          11       0.67      0.92      0.77        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.60      0.51      0.55        53\n",
      "          16       0.87      0.96      0.91        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.84      0.82      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.76      0.67      0.71      1542\n",
      "weighted avg       0.88      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[9/  300] loss: 0.013\n",
      "Average F1 score of the network: 0.8877\n",
      "Average recall_score score of the network: 0.8848\n",
      "Average precision_score score of the network: 0.9322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.85      0.49      0.62        35\n",
      "           3       0.72      0.52      0.61       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.88      0.74      0.80        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.74      0.52      0.61        77\n",
      "           9       0.91      0.68      0.78        44\n",
      "          10       0.72      0.54      0.62        48\n",
      "          11       0.57      0.92      0.71        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.73      0.45      0.56        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.86      0.82      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.81      0.85      1542\n",
      "   macro avg       0.77      0.67      0.71      1542\n",
      "weighted avg       0.89      0.81      0.84      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[9/  400] loss: 0.012\n",
      "Average F1 score of the network: 0.8885\n",
      "Average recall_score score of the network: 0.8918\n",
      "Average precision_score score of the network: 0.9263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.81      0.49      0.61        35\n",
      "           3       0.70      0.59      0.64       153\n",
      "           4       1.00      0.71      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.82      0.74      0.78        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.73      0.48      0.58        77\n",
      "           9       0.91      0.70      0.79        44\n",
      "          10       0.65      0.58      0.62        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.55      0.51      0.53        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.90      0.80      0.84        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.86      1542\n",
      "   macro avg       0.78      0.67      0.72      1542\n",
      "weighted avg       0.88      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[9/  500] loss: 0.012\n",
      "Average F1 score of the network: 0.8862\n",
      "Average recall_score score of the network: 0.8804\n",
      "Average precision_score score of the network: 0.9347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.64      0.51      0.57        35\n",
      "           3       0.73      0.46      0.56       153\n",
      "           4       1.00      0.71      0.83        42\n",
      "           5       0.96      0.87      0.91        30\n",
      "           6       0.93      0.74      0.82        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.75      0.52      0.62        77\n",
      "           9       0.97      0.68      0.80        44\n",
      "          10       0.72      0.58      0.64        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.55      0.49      0.52        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.90      0.82      0.86        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.90      0.81      0.85      1542\n",
      "   macro avg       0.77      0.67      0.71      1542\n",
      "weighted avg       0.89      0.81      0.84      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[9/  600] loss: 0.013\n",
      "Average F1 score of the network: 0.8905\n",
      "Average recall_score score of the network: 0.8896\n",
      "Average precision_score score of the network: 0.9320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.90      0.51      0.65        35\n",
      "           3       0.78      0.48      0.60       153\n",
      "           4       0.84      0.74      0.78        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.78      0.74      0.76        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.62      0.49      0.55        77\n",
      "           9       0.83      0.80      0.81        44\n",
      "          10       0.71      0.60      0.65        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.64      0.51      0.57        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.95      0.80      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.77      0.68      0.72      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[9/  700] loss: 0.015\n",
      "Average F1 score of the network: 0.8875\n",
      "Average recall_score score of the network: 0.8974\n",
      "Average precision_score score of the network: 0.9178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.63      0.49      0.55        35\n",
      "           3       0.68      0.63      0.65       153\n",
      "           4       0.94      0.71      0.81        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.79      0.71      0.75        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.72      0.51      0.60        77\n",
      "           9       0.91      0.73      0.81        44\n",
      "          10       0.58      0.60      0.59        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.51      0.57      0.54        53\n",
      "          16       0.84      0.96      0.90        27\n",
      "          17       0.93      0.91      0.92        55\n",
      "          18       0.82      0.84      0.83        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.87      0.83      0.85      1542\n",
      "   macro avg       0.75      0.69      0.71      1542\n",
      "weighted avg       0.87      0.83      0.85      1542\n",
      " samples avg       0.92      0.90      0.89      1542\n",
      "\n",
      "[9/  800] loss: 0.013\n",
      "Average F1 score of the network: 0.8896\n",
      "Average recall_score score of the network: 0.8879\n",
      "Average precision_score score of the network: 0.9319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.81      0.49      0.61        35\n",
      "           3       0.71      0.52      0.60       153\n",
      "           4       0.91      0.74      0.82        42\n",
      "           5       0.96      0.87      0.91        30\n",
      "           6       0.82      0.74      0.78        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.71      0.51      0.59        77\n",
      "           9       0.94      0.70      0.81        44\n",
      "          10       0.74      0.60      0.67        48\n",
      "          11       0.73      0.85      0.79        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.76      0.42      0.54        53\n",
      "          16       0.87      0.96      0.91        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.88      0.84      0.86        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.85      1542\n",
      "   macro avg       0.77      0.67      0.71      1542\n",
      "weighted avg       0.89      0.82      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[9/  900] loss: 0.014\n",
      "Average F1 score of the network: 0.8867\n",
      "Average recall_score score of the network: 0.8912\n",
      "Average precision_score score of the network: 0.9237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.70      0.46      0.55        35\n",
      "           3       0.70      0.52      0.60       153\n",
      "           4       0.86      0.74      0.79        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.79      0.71      0.75        38\n",
      "           7       0.95      0.95      0.95        39\n",
      "           8       0.64      0.48      0.55        77\n",
      "           9       0.83      0.77      0.80        44\n",
      "          10       0.68      0.62      0.65        48\n",
      "          11       0.75      0.92      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.69      0.47      0.56        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.84      0.84      0.84        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.88      0.82      0.85      1542\n",
      "   macro avg       0.75      0.68      0.71      1542\n",
      "weighted avg       0.87      0.82      0.84      1542\n",
      " samples avg       0.92      0.89      0.89      1542\n",
      "\n",
      "[9/ 1000] loss: 0.014\n",
      "Average F1 score of the network: 0.8921\n",
      "Average recall_score score of the network: 0.8871\n",
      "Average precision_score score of the network: 0.9389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.81      0.49      0.61        35\n",
      "           3       0.68      0.55      0.61       153\n",
      "           4       0.91      0.76      0.83        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.90      0.71      0.79        38\n",
      "           7       0.93      1.00      0.96        39\n",
      "           8       0.75      0.49      0.59        77\n",
      "           9       0.97      0.73      0.83        44\n",
      "          10       0.77      0.56      0.65        48\n",
      "          11       0.92      0.92      0.92        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.76      0.68      0.72        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.74      0.43      0.55        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.92      0.77      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.82      0.86      1542\n",
      "   macro avg       0.80      0.67      0.72      1542\n",
      "weighted avg       0.90      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[9/ 1100] loss: 0.015\n",
      "Average F1 score of the network: 0.8848\n",
      "Average recall_score score of the network: 0.8915\n",
      "Average precision_score score of the network: 0.9208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.81      0.49      0.61        35\n",
      "           3       0.66      0.58      0.62       153\n",
      "           4       0.76      0.74      0.75        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.69      0.76      0.72        38\n",
      "           7       0.95      0.95      0.95        39\n",
      "           8       0.55      0.60      0.57        77\n",
      "           9       1.00      0.68      0.81        44\n",
      "          10       0.68      0.56      0.61        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.68      0.47      0.56        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.93      0.91      0.92        55\n",
      "          18       0.90      0.82      0.86        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.87      0.82      0.85      1542\n",
      "   macro avg       0.75      0.68      0.71      1542\n",
      "weighted avg       0.87      0.82      0.84      1542\n",
      " samples avg       0.92      0.89      0.88      1542\n",
      "\n",
      "[9/ 1200] loss: 0.014\n",
      "Average F1 score of the network: 0.8814\n",
      "Average recall_score score of the network: 0.8844\n",
      "Average precision_score score of the network: 0.9205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.75      0.51      0.61        35\n",
      "           3       0.64      0.56      0.59       153\n",
      "           4       0.78      0.74      0.76        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.88      0.74      0.80        38\n",
      "           7       1.00      0.95      0.97        39\n",
      "           8       0.64      0.56      0.60        77\n",
      "           9       0.94      0.66      0.77        44\n",
      "          10       0.69      0.56      0.62        48\n",
      "          11       0.92      0.85      0.88        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.58      0.74        12\n",
      "          15       0.59      0.43      0.50        53\n",
      "          16       0.87      0.96      0.91        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.88      0.84      0.86        44\n",
      "          19       0.96      0.92      0.94        52\n",
      "\n",
      "   micro avg       0.88      0.82      0.85      1542\n",
      "   macro avg       0.77      0.66      0.71      1542\n",
      "weighted avg       0.87      0.82      0.84      1542\n",
      " samples avg       0.92      0.88      0.88      1542\n",
      "\n",
      "[9/ 1300] loss: 0.016\n",
      "Average F1 score of the network: 0.8857\n",
      "Average recall_score score of the network: 0.8885\n",
      "Average precision_score score of the network: 0.9268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.95       761\n",
      "           2       0.75      0.51      0.61        35\n",
      "           3       0.67      0.60      0.63       153\n",
      "           4       0.97      0.76      0.85        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.90      0.74      0.81        38\n",
      "           7       1.00      0.95      0.97        39\n",
      "           8       0.56      0.55      0.55        77\n",
      "           9       0.96      0.61      0.75        44\n",
      "          10       0.67      0.58      0.62        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.88      0.74      0.80        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.75      0.51      0.61        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.97      0.75      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.78      0.68      0.72      1542\n",
      "weighted avg       0.88      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[9/ 1400] loss: 0.013\n",
      "Average F1 score of the network: 0.8820\n",
      "Average recall_score score of the network: 0.8853\n",
      "Average precision_score score of the network: 0.9203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.95       761\n",
      "           2       0.77      0.49      0.60        35\n",
      "           3       0.66      0.55      0.60       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.68      0.74      0.71        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.68      0.44      0.54        77\n",
      "           9       0.91      0.68      0.78        44\n",
      "          10       0.69      0.56      0.62        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.88      0.74      0.80        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.56      0.53      0.54        53\n",
      "          16       0.79      0.96      0.87        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.88      0.80      0.83        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.88      0.81      0.84      1542\n",
      "   macro avg       0.75      0.68      0.71      1542\n",
      "weighted avg       0.87      0.81      0.84      1542\n",
      " samples avg       0.92      0.89      0.88      1542\n",
      "\n",
      "[9/ 1500] loss: 0.015\n",
      "Average F1 score of the network: 0.8900\n",
      "Average recall_score score of the network: 0.8884\n",
      "Average precision_score score of the network: 0.9331\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.77      0.49      0.60        35\n",
      "           3       0.69      0.54      0.61       153\n",
      "           4       0.94      0.76      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.78      0.74      0.76        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.71      0.47      0.56        77\n",
      "           9       0.97      0.66      0.78        44\n",
      "          10       0.74      0.54      0.63        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.86      0.63      0.73        19\n",
      "          14       0.91      0.83      0.87        12\n",
      "          15       0.74      0.43      0.55        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.88      0.82      0.85        44\n",
      "          19       0.98      0.96      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.78      0.68      0.72      1542\n",
      "weighted avg       0.88      0.82      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[9/ 1600] loss: 0.014\n",
      "Average F1 score of the network: 0.8879\n",
      "Average recall_score score of the network: 0.8897\n",
      "Average precision_score score of the network: 0.9284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.64      0.51      0.57       153\n",
      "           4       0.87      0.79      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.76      0.74      0.75        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.70      0.52      0.60        77\n",
      "           9       0.94      0.77      0.85        44\n",
      "          10       0.60      0.67      0.63        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.91      0.83      0.87        12\n",
      "          15       0.64      0.51      0.57        53\n",
      "          16       0.76      0.96      0.85        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.92      0.82      0.87        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.88      0.82      0.85      1542\n",
      "   macro avg       0.76      0.69      0.72      1542\n",
      "weighted avg       0.88      0.82      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[9/ 1700] loss: 0.017\n",
      "Average F1 score of the network: 0.8861\n",
      "Average recall_score score of the network: 0.8962\n",
      "Average precision_score score of the network: 0.9202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.93      0.96      0.95       761\n",
      "           2       0.68      0.49      0.57        35\n",
      "           3       0.67      0.52      0.59       153\n",
      "           4       0.89      0.76      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.74      0.74      0.74        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.63      0.53      0.58        77\n",
      "           9       0.97      0.77      0.86        44\n",
      "          10       0.59      0.60      0.60        48\n",
      "          11       0.67      0.92      0.77        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.65      0.53      0.58        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.94      0.89      0.92        55\n",
      "          18       0.90      0.84      0.87        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.87      0.83      0.85      1542\n",
      "   macro avg       0.75      0.69      0.71      1542\n",
      "weighted avg       0.86      0.83      0.84      1542\n",
      " samples avg       0.92      0.90      0.89      1542\n",
      "\n",
      "[9/ 1800] loss: 0.014\n",
      "Average F1 score of the network: 0.8806\n",
      "Average recall_score score of the network: 0.8859\n",
      "Average precision_score score of the network: 0.9206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.94       761\n",
      "           2       0.76      0.46      0.57        35\n",
      "           3       0.66      0.56      0.61       153\n",
      "           4       0.89      0.79      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.82      0.74      0.78        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.65      0.51      0.57        77\n",
      "           9       0.92      0.75      0.83        44\n",
      "          10       0.68      0.54      0.60        48\n",
      "          11       0.75      0.92      0.83        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.53      0.55      0.54        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.97      0.80      0.88        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.88      0.82      0.85      1542\n",
      "   macro avg       0.76      0.68      0.72      1542\n",
      "weighted avg       0.87      0.82      0.84      1542\n",
      " samples avg       0.92      0.89      0.88      1542\n",
      "\n",
      "[10/  100] loss: 0.009\n",
      "Average F1 score of the network: 0.8864\n",
      "Average recall_score score of the network: 0.8830\n",
      "Average precision_score score of the network: 0.9320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.95       761\n",
      "           2       0.80      0.46      0.58        35\n",
      "           3       0.74      0.53      0.62       153\n",
      "           4       0.91      0.76      0.83        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.87      0.71      0.78        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.69      0.48      0.56        77\n",
      "           9       0.91      0.73      0.81        44\n",
      "          10       0.67      0.60      0.64        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.75      0.86        12\n",
      "          15       0.58      0.47      0.52        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.85      0.80      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.81      0.85      1542\n",
      "   macro avg       0.78      0.67      0.72      1542\n",
      "weighted avg       0.89      0.81      0.84      1542\n",
      " samples avg       0.93      0.88      0.89      1542\n",
      "\n",
      "[10/  200] loss: 0.008\n",
      "Average F1 score of the network: 0.8864\n",
      "Average recall_score score of the network: 0.8872\n",
      "Average precision_score score of the network: 0.9271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.63      0.58      0.60       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.79      0.71      0.75        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.70      0.45      0.55        77\n",
      "           9       0.91      0.70      0.79        44\n",
      "          10       0.64      0.62      0.63        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.64      0.47      0.54        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.88      0.80      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.88      0.82      0.85      1542\n",
      "   macro avg       0.78      0.67      0.71      1542\n",
      "weighted avg       0.88      0.82      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[10/  300] loss: 0.008\n",
      "Average F1 score of the network: 0.8879\n",
      "Average recall_score score of the network: 0.8855\n",
      "Average precision_score score of the network: 0.9305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.95       761\n",
      "           2       0.76      0.46      0.57        35\n",
      "           3       0.63      0.54      0.58       153\n",
      "           4       1.00      0.74      0.85        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.80      0.74      0.77        38\n",
      "           7       0.95      0.95      0.95        39\n",
      "           8       0.76      0.45      0.57        77\n",
      "           9       0.97      0.73      0.83        44\n",
      "          10       0.69      0.65      0.67        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.68      0.53      0.60        53\n",
      "          16       0.87      0.96      0.91        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.88      0.82      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.79      0.68      0.72      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[10/  400] loss: 0.008\n",
      "Average F1 score of the network: 0.8845\n",
      "Average recall_score score of the network: 0.8938\n",
      "Average precision_score score of the network: 0.9176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.89      0.46      0.60        35\n",
      "           3       0.59      0.58      0.59       153\n",
      "           4       1.00      0.76      0.86        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.72      0.74      0.73        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.61      0.51      0.55        77\n",
      "           9       0.94      0.75      0.84        44\n",
      "          10       0.69      0.60      0.64        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.81      0.68      0.74        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.64      0.51      0.57        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.90      0.80      0.84        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.87      0.83      0.85      1542\n",
      "   macro avg       0.77      0.68      0.72      1542\n",
      "weighted avg       0.87      0.83      0.84      1542\n",
      " samples avg       0.92      0.89      0.88      1542\n",
      "\n",
      "[10/  500] loss: 0.008\n",
      "Average F1 score of the network: 0.8935\n",
      "Average recall_score score of the network: 0.8915\n",
      "Average precision_score score of the network: 0.9359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.81      0.49      0.61        35\n",
      "           3       0.72      0.55      0.62       153\n",
      "           4       0.94      0.74      0.83        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.90      0.74      0.81        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.71      0.52      0.60        77\n",
      "           9       0.95      0.82      0.88        44\n",
      "          10       0.68      0.52      0.59        48\n",
      "          11       0.69      0.85      0.76        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.71      0.51      0.59        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.96      0.89      0.92        55\n",
      "          18       0.85      0.80      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.90      0.82      0.86      1542\n",
      "   macro avg       0.78      0.68      0.72      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.94      0.89      0.89      1542\n",
      "\n",
      "[10/  600] loss: 0.010\n",
      "Average F1 score of the network: 0.8846\n",
      "Average recall_score score of the network: 0.8874\n",
      "Average precision_score score of the network: 0.9239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.65      0.53      0.58       153\n",
      "           4       0.89      0.76      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.78      0.74      0.76        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.60      0.49      0.54        77\n",
      "           9       0.94      0.75      0.84        44\n",
      "          10       0.74      0.54      0.63        48\n",
      "          11       0.79      0.85      0.81        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.60      0.49      0.54        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.90      0.80      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.88      0.82      0.85      1542\n",
      "   macro avg       0.78      0.67      0.71      1542\n",
      "weighted avg       0.87      0.82      0.84      1542\n",
      " samples avg       0.92      0.89      0.88      1542\n",
      "\n",
      "[10/  700] loss: 0.011\n",
      "Average F1 score of the network: 0.8810\n",
      "Average recall_score score of the network: 0.8865\n",
      "Average precision_score score of the network: 0.9183\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.94      0.94       761\n",
      "           2       0.69      0.51      0.59        35\n",
      "           3       0.66      0.53      0.59       153\n",
      "           4       0.97      0.71      0.82        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.87      0.71      0.78        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.70      0.43      0.53        77\n",
      "           9       0.92      0.77      0.84        44\n",
      "          10       0.66      0.65      0.65        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.76      0.68      0.72        19\n",
      "          14       0.91      0.83      0.87        12\n",
      "          15       0.46      0.55      0.50        53\n",
      "          16       0.90      0.96      0.93        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.95      0.82      0.88        44\n",
      "          19       0.94      0.94      0.94        52\n",
      "\n",
      "   micro avg       0.88      0.82      0.85      1542\n",
      "   macro avg       0.75      0.69      0.71      1542\n",
      "weighted avg       0.87      0.82      0.84      1542\n",
      " samples avg       0.92      0.89      0.88      1542\n",
      "\n",
      "[10/  800] loss: 0.014\n",
      "Average F1 score of the network: 0.8918\n",
      "Average recall_score score of the network: 0.8805\n",
      "Average precision_score score of the network: 0.9431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.96      0.95       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.86      0.42      0.56       153\n",
      "           4       0.89      0.74      0.81        42\n",
      "           5       0.97      0.97      0.97        30\n",
      "           6       0.77      0.71      0.74        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.69      0.52      0.59        77\n",
      "           9       0.94      0.68      0.79        44\n",
      "          10       0.67      0.60      0.64        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.68      0.81        19\n",
      "          14       1.00      0.75      0.86        12\n",
      "          15       0.83      0.45      0.59        53\n",
      "          16       0.87      0.96      0.91        27\n",
      "          17       0.98      0.91      0.94        55\n",
      "          18       0.92      0.75      0.83        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.81      0.86      1542\n",
      "   macro avg       0.80      0.67      0.72      1542\n",
      "weighted avg       0.91      0.81      0.84      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[10/  900] loss: 0.012\n",
      "Average F1 score of the network: 0.8874\n",
      "Average recall_score score of the network: 0.8776\n",
      "Average precision_score score of the network: 0.9384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.94      0.95       761\n",
      "           2       0.80      0.46      0.58        35\n",
      "           3       0.76      0.48      0.59       153\n",
      "           4       0.89      0.76      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.78      0.74      0.76        38\n",
      "           7       0.97      0.95      0.96        39\n",
      "           8       0.72      0.44      0.55        77\n",
      "           9       0.94      0.70      0.81        44\n",
      "          10       0.62      0.58      0.60        48\n",
      "          11       0.67      0.92      0.77        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.73      0.45      0.56        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.98      0.91      0.94        55\n",
      "          18       0.89      0.75      0.81        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.91      0.80      0.85      1542\n",
      "   macro avg       0.78      0.66      0.71      1542\n",
      "weighted avg       0.90      0.80      0.84      1542\n",
      " samples avg       0.94      0.88      0.89      1542\n",
      "\n",
      "[10/ 1000] loss: 0.012\n",
      "Average F1 score of the network: 0.8923\n",
      "Average recall_score score of the network: 0.8912\n",
      "Average precision_score score of the network: 0.9330\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.72      0.51      0.60        35\n",
      "           3       0.70      0.51      0.59       153\n",
      "           4       0.89      0.79      0.84        42\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       0.85      0.74      0.79        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.69      0.52      0.59        77\n",
      "           9       0.94      0.73      0.82        44\n",
      "          10       0.72      0.60      0.66        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.76      0.68      0.72        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.73      0.45      0.56        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.98      0.91      0.94        55\n",
      "          18       0.86      0.82      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.86      1542\n",
      "   macro avg       0.77      0.69      0.72      1542\n",
      "weighted avg       0.88      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[10/ 1100] loss: 0.010\n",
      "Average F1 score of the network: 0.8862\n",
      "Average recall_score score of the network: 0.8917\n",
      "Average precision_score score of the network: 0.9220\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.96      0.95       761\n",
      "           2       0.70      0.46      0.55        35\n",
      "           3       0.68      0.53      0.60       153\n",
      "           4       0.87      0.79      0.82        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.87      0.71      0.78        38\n",
      "           7       0.95      0.97      0.96        39\n",
      "           8       0.62      0.51      0.56        77\n",
      "           9       0.94      0.68      0.79        44\n",
      "          10       0.56      0.67      0.61        48\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.75      0.86        12\n",
      "          15       0.58      0.49      0.53        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.92      0.80      0.85        44\n",
      "          19       0.96      0.94      0.95        52\n",
      "\n",
      "   micro avg       0.87      0.83      0.85      1542\n",
      "   macro avg       0.76      0.68      0.71      1542\n",
      "weighted avg       0.87      0.83      0.84      1542\n",
      " samples avg       0.92      0.89      0.89      1542\n",
      "\n",
      "[10/ 1200] loss: 0.013\n",
      "Average F1 score of the network: 0.8864\n",
      "Average recall_score score of the network: 0.8859\n",
      "Average precision_score score of the network: 0.9292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.93      0.95       761\n",
      "           2       0.63      0.49      0.55        35\n",
      "           3       0.64      0.60      0.62       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       0.90      0.71      0.79        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.66      0.53      0.59        77\n",
      "           9       0.97      0.70      0.82        44\n",
      "          10       0.67      0.65      0.66        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.68      0.43      0.53        53\n",
      "          16       1.00      0.96      0.98        27\n",
      "          17       0.91      0.91      0.91        55\n",
      "          18       0.91      0.68      0.78        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.85      1542\n",
      "   macro avg       0.78      0.67      0.72      1542\n",
      "weighted avg       0.89      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[10/ 1300] loss: 0.014\n",
      "Average F1 score of the network: 0.8911\n",
      "Average recall_score score of the network: 0.8923\n",
      "Average precision_score score of the network: 0.9310\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.96      0.95       761\n",
      "           2       0.84      0.46      0.59        35\n",
      "           3       0.70      0.50      0.58       153\n",
      "           4       0.94      0.79      0.86        42\n",
      "           5       0.94      0.97      0.95        30\n",
      "           6       0.82      0.74      0.78        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.65      0.56      0.60        77\n",
      "           9       0.87      0.77      0.82        44\n",
      "          10       0.72      0.58      0.64        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.63      0.77        19\n",
      "          14       1.00      0.75      0.86        12\n",
      "          15       0.63      0.45      0.53        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.90      0.80      0.84        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.82      0.86      1542\n",
      "   macro avg       0.78      0.68      0.72      1542\n",
      "weighted avg       0.88      0.82      0.85      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[10/ 1400] loss: 0.012\n",
      "Average F1 score of the network: 0.8862\n",
      "Average recall_score score of the network: 0.8885\n",
      "Average precision_score score of the network: 0.9266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.97      0.94      0.96       761\n",
      "           2       0.76      0.46      0.57        35\n",
      "           3       0.63      0.54      0.58       153\n",
      "           4       0.97      0.79      0.87        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.82      0.74      0.78        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.61      0.52      0.56        77\n",
      "           9       0.89      0.73      0.80        44\n",
      "          10       0.62      0.58      0.60        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.87      0.68      0.76        19\n",
      "          14       1.00      0.83      0.91        12\n",
      "          15       0.59      0.45      0.51        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.96      0.91      0.93        55\n",
      "          18       0.85      0.80      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.88      0.82      0.85      1542\n",
      "   macro avg       0.76      0.68      0.72      1542\n",
      "weighted avg       0.88      0.82      0.84      1542\n",
      " samples avg       0.93      0.89      0.89      1542\n",
      "\n",
      "[10/ 1500] loss: 0.012\n",
      "Average F1 score of the network: 0.8815\n",
      "Average recall_score score of the network: 0.8867\n",
      "Average precision_score score of the network: 0.9208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.95      0.95       761\n",
      "           2       0.73      0.46      0.56        35\n",
      "           3       0.62      0.47      0.54       153\n",
      "           4       0.97      0.79      0.87        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.90      0.71      0.79        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.58      0.52      0.55        77\n",
      "           9       0.97      0.75      0.85        44\n",
      "          10       0.67      0.60      0.64        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.75      0.86        12\n",
      "          15       0.53      0.49      0.51        53\n",
      "          16       0.96      0.93      0.94        27\n",
      "          17       0.94      0.91      0.93        55\n",
      "          18       0.85      0.80      0.82        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.87      0.82      0.84      1542\n",
      "   macro avg       0.77      0.68      0.72      1542\n",
      "weighted avg       0.87      0.82      0.84      1542\n",
      " samples avg       0.92      0.89      0.88      1542\n",
      "\n",
      "[10/ 1600] loss: 0.013\n",
      "Average F1 score of the network: 0.8845\n",
      "Average recall_score score of the network: 0.8822\n",
      "Average precision_score score of the network: 0.9295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.93      0.95       761\n",
      "           2       0.76      0.46      0.57        35\n",
      "           3       0.61      0.52      0.56       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.88      0.74      0.80        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.69      0.49      0.58        77\n",
      "           9       0.94      0.70      0.81        44\n",
      "          10       0.64      0.62      0.63        48\n",
      "          11       0.67      0.92      0.77        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.93      0.68      0.79        19\n",
      "          14       1.00      0.67      0.80        12\n",
      "          15       0.72      0.43      0.54        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.88      0.82      0.85        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.89      0.81      0.85      1542\n",
      "   macro avg       0.78      0.67      0.71      1542\n",
      "weighted avg       0.89      0.81      0.84      1542\n",
      " samples avg       0.93      0.88      0.88      1542\n",
      "\n",
      "[10/ 1700] loss: 0.013\n",
      "Average F1 score of the network: 0.8832\n",
      "Average recall_score score of the network: 0.8923\n",
      "Average precision_score score of the network: 0.9161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.69      0.51      0.59        35\n",
      "           3       0.59      0.62      0.60       153\n",
      "           4       1.00      0.76      0.86        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.87      0.71      0.78        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.61      0.56      0.58        77\n",
      "           9       1.00      0.68      0.81        44\n",
      "          10       0.68      0.56      0.61        48\n",
      "          11       0.80      0.92      0.86        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       0.73      0.67      0.70        12\n",
      "          15       0.60      0.51      0.55        53\n",
      "          16       0.96      0.96      0.96        27\n",
      "          17       0.98      0.87      0.92        55\n",
      "          18       0.92      0.77      0.84        44\n",
      "          19       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.87      0.83      0.85      1542\n",
      "   macro avg       0.76      0.68      0.71      1542\n",
      "weighted avg       0.87      0.83      0.85      1542\n",
      " samples avg       0.92      0.89      0.88      1542\n",
      "\n",
      "[10/ 1800] loss: 0.015\n",
      "Average F1 score of the network: 0.8836\n",
      "Average recall_score score of the network: 0.8956\n",
      "Average precision_score score of the network: 0.9151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.94      0.96      0.95       761\n",
      "           2       0.47      0.60      0.52        35\n",
      "           3       0.64      0.50      0.56       153\n",
      "           4       0.97      0.74      0.84        42\n",
      "           5       0.96      0.90      0.93        30\n",
      "           6       0.74      0.74      0.74        38\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.60      0.53      0.57        77\n",
      "           9       0.86      0.73      0.79        44\n",
      "          10       0.61      0.62      0.62        48\n",
      "          11       0.86      0.92      0.89        13\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.92      0.63      0.75        19\n",
      "          14       0.90      0.75      0.82        12\n",
      "          15       0.55      0.49      0.52        53\n",
      "          16       0.93      0.96      0.95        27\n",
      "          17       0.98      0.89      0.93        55\n",
      "          18       0.97      0.77      0.86        44\n",
      "          19       1.00      0.94      0.97        52\n",
      "\n",
      "   micro avg       0.86      0.83      0.84      1542\n",
      "   macro avg       0.74      0.68      0.71      1542\n",
      "weighted avg       0.86      0.83      0.84      1542\n",
      " samples avg       0.92      0.90      0.88      1542\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in trange(n_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    just_for_curious = []\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        features, labels = data\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(features.float())\n",
    "        label_renewed = torch.cat((labels[:, 1:12], labels[:, 13:]), 1)\n",
    "        loss = criterion(outputs, label_renewed)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # ema.update(net)\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print(f'[{epoch + 1}/{i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            validate()\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all above cells to get result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following section is just for examine purpose. Running them might affect the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. machine learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-multilearn\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.zeros((len(train_set.combined_feature), 1024))\n",
    "train_y = np.array(train_set.labels_train)\n",
    "for i in range(len(train_x)):\n",
    "    train_x[i, :] = np.array(train_set.combined_feature[i].squeeze())\n",
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 methods tryout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "parameters = {'n_neighbors': (3, 5, 10, 20)}\n",
    "score = 'f1_samples'\n",
    "clf = GridSearchCV(KNeighborsClassifier(), parameters, scoring=score, verbose=10)\n",
    "clf.fit(train_x, train_y)\n",
    "print (clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "parameters = {'max_depth': (1, 3, 5, 10), \"n_estimators\": (50, 100 ,200)}\n",
    "score = 'f1_samples'\n",
    "clf = GridSearchCV(RandomForestClassifier(), parameters, scoring=score, verbose=10)\n",
    "clf.fit(train_x, train_y)\n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = []\n",
    "for i in trange(len(test_set)):\n",
    "    test_input = np.array(test_set.combined_feature[i])\n",
    "    predictions.append(clf.predict(test_input))\n",
    "\n",
    "for i in trange(len(test_set)):\n",
    "    label = \"\"\n",
    "    for j in range(len(predictions[i][0])):\n",
    "        if predictions[i][0][j] == 1:\n",
    "            label += \"{} \".format(j)\n",
    "    predictions[i] = label.rstrip(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 save result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test) as file:\n",
    "    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
    "    df2 = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
    "\n",
    "df = pd.DataFrame({\"ImageID\": df2.ImageID, 'Labels': predictions})\n",
    "df.to_csv('result_ml.csv', index=False)\n",
    "print(\"successfully saved to 'result_ml.csv'\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. car detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade tencentcloud-sdk-python\n",
    "\n",
    "import json\n",
    "import base64\n",
    "from tencentcloud.common import credential\n",
    "from tencentcloud.common.profile.client_profile import ClientProfile\n",
    "from tencentcloud.common.profile.http_profile import HttpProfile\n",
    "from tencentcloud.common.exception.tencent_cloud_sdk_exception import TencentCloudSDKException\n",
    "from tencentcloud.tiia.v20190529 import tiia_client, models\n",
    "\n",
    "def get_result(image_base64):\n",
    "    try:\n",
    "        cred = credential.Credential(\"\", \"\")\n",
    "        httpProfile = HttpProfile()\n",
    "        httpProfile.endpoint = \"tiia.tencentcloudapi.com\"\n",
    "\n",
    "        clientProfile = ClientProfile()\n",
    "        clientProfile.httpProfile = httpProfile\n",
    "        client = tiia_client.TiiaClient(cred, \"ap-guangzhou\", clientProfile)\n",
    "\n",
    "        req = models.RecognizeCarProRequest()\n",
    "        params = {\"ImageBase64\": image_base64}\n",
    "        req.from_json_string(json.dumps(params))\n",
    "\n",
    "        resp = json.loads(client.RecognizeCarPro(req).to_json_string())\n",
    "        print(resp)\n",
    "\n",
    "        return True\n",
    "\n",
    "    except TencentCloudSDKException as err:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_result = []\n",
    "with open(test) as file:\n",
    "    lines=[line for line in file]\n",
    "    df_test_api = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")[:30]\n",
    "\n",
    "    image_raw = df_test_api.ImageID\n",
    "    for i in trange(len(df_test_api)):\n",
    "        with open(\"./data/{}\".format(image_raw[i]),\"rb\") as image:\n",
    "            image = image.read()\n",
    "            image_base64 = base64.encodebytes(image).decode(\"utf-8\")\n",
    "            result = get_result(image_base64)\n",
    "            if result:\n",
    "                api_result.append((image_raw[i], result))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
